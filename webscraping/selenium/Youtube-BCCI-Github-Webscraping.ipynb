{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c9e3533-75ac-4eb9-8041-8ff1eafe4b8b",
   "metadata": {},
   "source": [
    "# Youtube, BCCI, Github Web Scraping \n",
    "by --- Mohammed Ikramuddin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba65ca83-8b31-4519-8fab-00804b3fffd3",
   "metadata": {},
   "source": [
    "Q1. Scrape the details of most viewed videos on YouTube from Wikipedia.\n",
    "\n",
    "Url = https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos You need to find following details:\n",
    "\n",
    "A) Rank\n",
    "B) Name\n",
    "C) Artist\n",
    "D) Upload date\n",
    "E) Views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "991ca5d3-7e5c-43ff-b18f-6047a7526b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing Selenium, pandas, selenium webdriver, warnings, and time\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import requests\n",
    "import re\n",
    "\n",
    "#importing selenium webdriver\n",
    "from selenium import webdriver\n",
    "\n",
    "#importing warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from time import sleep\n",
    "from selenium.webdriver import ActionChains\n",
    "from selenium.webdriver.common.actions.action_builder import ActionBuilder\n",
    "from selenium.webdriver.common.actions.mouse_button import MouseButton\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "#Importing Exceptions\n",
    "from selenium.common.exceptions import NoSuchElementException as NSEE\n",
    "from selenium.common.exceptions import StaleElementReferenceException as SERE\n",
    "from selenium.common.exceptions import ElementNotInteractableException as ENIE\n",
    "from selenium.common.exceptions import TimeoutException as TE\n",
    "from selenium.common.exceptions import InvalidSelectorException as ISE\n",
    "from selenium.common.exceptions import ElementClickInterceptedException as ECIE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5631443-4853-44c7-b8ad-634e9e936058",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping Youtube video names\n",
    "wiki_driver = webdriver.Chrome() #opening automated chrome browser using selenium driver\n",
    "wiki_driver.maximize_window() #maximize window\n",
    "url =  'https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos' #url\n",
    "wiki_driver.get(url) #opening the webpage on automated chrome browser\n",
    "time.sleep(2) #asking driver to wait for 2 seconds\n",
    "\n",
    "#Declaring lists\n",
    "video_rank = []\n",
    "video_name = []\n",
    "video_artist = []\n",
    "video_upload_date = []\n",
    "video_views = []\n",
    "\n",
    "#scraping for videos and assigning rank in ascending order from the wiki page table\n",
    "j = 1\n",
    "rank = wiki_driver.find_elements(By.XPATH, '//table[@class=\"sortable wikitable sticky-header static-row-numbers sort-under col3center col4right jquery-tablesorter\"]/tbody/tr')\n",
    "for i in rank:\n",
    "    try:\n",
    "        video_rank.append(j)\n",
    "        j=j+1\n",
    "    except NSEE:\n",
    "        video_rank.append('--')\n",
    "    except SERE:\n",
    "        video_rank.append('--')\n",
    "    except ENIE:\n",
    "        video_rank.append('--')\n",
    "    except TE:\n",
    "        video_rank.append('--')\n",
    "    except ISE:\n",
    "        video_rank.append('--')\n",
    "    except ECIE:\n",
    "        video_rank.append('--')\n",
    "\n",
    "#scraping for video name from the wiki page table\n",
    "name = wiki_driver.find_elements(By.XPATH, '//table[@class=\"sortable wikitable sticky-header static-row-numbers sort-under col3center col4right jquery-tablesorter\"]/tbody/tr/td[1]')\n",
    "for i in name:\n",
    "    try:\n",
    "        v_name = re.sub(\"[\\(\\[].*?[\\)\\]]\", \"\", i.text)\n",
    "        video_name.append(v_name)\n",
    "    except NSEE:\n",
    "        video_name.append('--')\n",
    "    except SERE:\n",
    "        video_name.append('--')\n",
    "    except ENIE:\n",
    "        video_name.append('--')\n",
    "    except TE:\n",
    "        video_name.append('--')\n",
    "    except ISE:\n",
    "        video_name.append('--')\n",
    "    except ECIE:\n",
    "        video_name.append('--')\n",
    "\n",
    "#scraping for video artist from the wiki page table\n",
    "artist = wiki_driver.find_elements(By.XPATH, '//table[@class=\"sortable wikitable sticky-header static-row-numbers sort-under col3center col4right jquery-tablesorter\"]/tbody/tr/td[2]')\n",
    "for i in artist:\n",
    "    try:\n",
    "        video_artist.append(i.text)\n",
    "    except NSEE:\n",
    "        video_artist.append('--')\n",
    "    except SERE:\n",
    "        video_artist.append('--')\n",
    "    except ENIE:\n",
    "        video_artist.append('--')\n",
    "    except TE:\n",
    "        video_artist.append('--')\n",
    "    except ISE:\n",
    "        video_artist.append('--')\n",
    "    except ECIE:\n",
    "        video_artist.append('--')\n",
    "\n",
    "#scraping for video upload date from the wiki page table\n",
    "upload_date = wiki_driver.find_elements(By.XPATH, '//table[@class=\"sortable wikitable sticky-header static-row-numbers sort-under col3center col4right jquery-tablesorter\"]/tbody/tr/td[4]')\n",
    "for i in upload_date:\n",
    "    try:\n",
    "        video_upload_date.append(i.text)\n",
    "    except NSEE:\n",
    "        video_upload_date.append('--')\n",
    "    except SERE:\n",
    "        video_upload_date.append('--')\n",
    "    except ENIE:\n",
    "        video_upload_date.append('--')\n",
    "    except TE:\n",
    "        video_upload_date.append('--')\n",
    "    except ISE:\n",
    "        video_upload_date.append('--')\n",
    "    except ECIE:\n",
    "        video_upload_date.append('--')\n",
    "\n",
    "#scraping for video views from the wiki page table\n",
    "views = wiki_driver.find_elements(By.XPATH, '//table[@class=\"sortable wikitable sticky-header static-row-numbers sort-under col3center col4right jquery-tablesorter\"]/tbody/tr/td[3]')\n",
    "for i in views:\n",
    "    try:\n",
    "        video_views.append(i.text)\n",
    "    except NSEE:\n",
    "        video_views.append('--')\n",
    "    except SERE:\n",
    "        video_views.append('--')\n",
    "    except ENIE:\n",
    "        video_views.append('--')\n",
    "    except TE:\n",
    "        video_views.append('--')\n",
    "    except ISE:\n",
    "        video_views.append('--')\n",
    "    except ECIE:\n",
    "        video_views.append('--')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c1b3517-76e0-4796-9f21-0aa70023797b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 30 30 30 30\n"
     ]
    }
   ],
   "source": [
    "print(len(video_rank), len(video_name), len(video_artist), len(video_upload_date), len(video_views))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9aefa2af-6292-4377-9356-8216ce307b66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Video Rank</th>\n",
       "      <th>Name</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Upload Date</th>\n",
       "      <th>Views (Billions)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>\"Baby Shark Dance\"</td>\n",
       "      <td>Pinkfong Baby Shark - Kids' Songs &amp; Stories</td>\n",
       "      <td>June 17, 2016</td>\n",
       "      <td>14.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>\"Despacito\"</td>\n",
       "      <td>Luis Fonsi</td>\n",
       "      <td>January 12, 2017</td>\n",
       "      <td>8.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>\"Johny Johny Yes Papa\"</td>\n",
       "      <td>LooLoo Kids - Nursery Rhymes and Children's Songs</td>\n",
       "      <td>October 8, 2016</td>\n",
       "      <td>6.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>\"Bath Song\"</td>\n",
       "      <td>Cocomelon - Nursery Rhymes</td>\n",
       "      <td>May 2, 2018</td>\n",
       "      <td>6.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>\"Shape of You\"</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>January 30, 2017</td>\n",
       "      <td>6.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>\"See You Again\"</td>\n",
       "      <td>Wiz Khalifa</td>\n",
       "      <td>April 6, 2015</td>\n",
       "      <td>6.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>\"Wheels on the Bus\"</td>\n",
       "      <td>Cocomelon - Nursery Rhymes</td>\n",
       "      <td>May 24, 2018</td>\n",
       "      <td>6.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>\"Phonics Song with Two Words\"</td>\n",
       "      <td>ChuChu TV Nursery Rhymes &amp; Kids Songs</td>\n",
       "      <td>March 6, 2014</td>\n",
       "      <td>5.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>\"Uptown Funk\"</td>\n",
       "      <td>Mark Ronson</td>\n",
       "      <td>November 19, 2014</td>\n",
       "      <td>5.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>\"Gangnam Style\"</td>\n",
       "      <td>Psy</td>\n",
       "      <td>July 15, 2012</td>\n",
       "      <td>5.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>\"Learning Colors – Colorful Eggs on a Farm\"</td>\n",
       "      <td>Miroshka TV</td>\n",
       "      <td>February 27, 2018</td>\n",
       "      <td>5.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>\"Dame Tu Cosita\"</td>\n",
       "      <td>Ultra Records</td>\n",
       "      <td>April 5, 2018</td>\n",
       "      <td>4.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>\"Masha and the Bear – Recipe for Disaster\"</td>\n",
       "      <td>Get Movies</td>\n",
       "      <td>January 31, 2012</td>\n",
       "      <td>4.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>\"Axel F\"</td>\n",
       "      <td>Crazy Frog</td>\n",
       "      <td>June 16, 2009</td>\n",
       "      <td>4.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>\"Sugar\"</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>January 14, 2015</td>\n",
       "      <td>4.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>\"Baa Baa Black Sheep\"</td>\n",
       "      <td>Cocomelon - Nursery Rhymes</td>\n",
       "      <td>June 25, 2018</td>\n",
       "      <td>4.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>\"Counting Stars\"</td>\n",
       "      <td>OneRepublic</td>\n",
       "      <td>May 31, 2013</td>\n",
       "      <td>4.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>\"Lakdi Ki Kathi\"</td>\n",
       "      <td>Jingle Toons</td>\n",
       "      <td>June 14, 2018</td>\n",
       "      <td>3.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>\"Roar\"</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>September 5, 2013</td>\n",
       "      <td>3.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>\"Waka Waka \"</td>\n",
       "      <td>Shakira</td>\n",
       "      <td>June 4, 2010</td>\n",
       "      <td>3.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>\"Sorry\"</td>\n",
       "      <td>Justin Bieber</td>\n",
       "      <td>October 22, 2015</td>\n",
       "      <td>3.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>\"Shree Hanuman Chalisa\"</td>\n",
       "      <td>T-Series Bhakti Sagar</td>\n",
       "      <td>May 10, 2011</td>\n",
       "      <td>3.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>\"Humpty the train on a fruits ride\"</td>\n",
       "      <td>Kiddiestv Hindi - Nursery Rhymes &amp; Kids Songs</td>\n",
       "      <td>January 26, 2018</td>\n",
       "      <td>3.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>\"Thinking Out Loud\"</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>October 7, 2014</td>\n",
       "      <td>3.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>\"Perfect\"</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>November 9, 2017</td>\n",
       "      <td>3.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>\"Dark Horse\"</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>February 20, 2014</td>\n",
       "      <td>3.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>\"Let Her Go\"</td>\n",
       "      <td>Passenger</td>\n",
       "      <td>July 25, 2012</td>\n",
       "      <td>3.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>\"Faded\"</td>\n",
       "      <td>Alan Walker</td>\n",
       "      <td>December 3, 2015</td>\n",
       "      <td>3.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>\"Girls Like You\"</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>May 31, 2018</td>\n",
       "      <td>3.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>\"Lean On\"</td>\n",
       "      <td>Major Lazer Official</td>\n",
       "      <td>March 22, 2015</td>\n",
       "      <td>3.57</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Video Rank                                         Name  \\\n",
       "0            1                           \"Baby Shark Dance\"   \n",
       "1            2                                  \"Despacito\"   \n",
       "2            3                       \"Johny Johny Yes Papa\"   \n",
       "3            4                                  \"Bath Song\"   \n",
       "4            5                               \"Shape of You\"   \n",
       "5            6                              \"See You Again\"   \n",
       "6            7                          \"Wheels on the Bus\"   \n",
       "7            8                \"Phonics Song with Two Words\"   \n",
       "8            9                                \"Uptown Funk\"   \n",
       "9           10                              \"Gangnam Style\"   \n",
       "10          11  \"Learning Colors – Colorful Eggs on a Farm\"   \n",
       "11          12                             \"Dame Tu Cosita\"   \n",
       "12          13   \"Masha and the Bear – Recipe for Disaster\"   \n",
       "13          14                                     \"Axel F\"   \n",
       "14          15                                      \"Sugar\"   \n",
       "15          16                        \"Baa Baa Black Sheep\"   \n",
       "16          17                             \"Counting Stars\"   \n",
       "17          18                             \"Lakdi Ki Kathi\"   \n",
       "18          19                                       \"Roar\"   \n",
       "19          20                                 \"Waka Waka \"   \n",
       "20          21                                      \"Sorry\"   \n",
       "21          22                      \"Shree Hanuman Chalisa\"   \n",
       "22          23          \"Humpty the train on a fruits ride\"   \n",
       "23          24                          \"Thinking Out Loud\"   \n",
       "24          25                                    \"Perfect\"   \n",
       "25          26                                 \"Dark Horse\"   \n",
       "26          27                                 \"Let Her Go\"   \n",
       "27          28                                      \"Faded\"   \n",
       "28          29                             \"Girls Like You\"   \n",
       "29          30                                    \"Lean On\"   \n",
       "\n",
       "                                               Artist        Upload Date  \\\n",
       "0         Pinkfong Baby Shark - Kids' Songs & Stories      June 17, 2016   \n",
       "1                                          Luis Fonsi   January 12, 2017   \n",
       "2   LooLoo Kids - Nursery Rhymes and Children's Songs    October 8, 2016   \n",
       "3                          Cocomelon - Nursery Rhymes        May 2, 2018   \n",
       "4                                          Ed Sheeran   January 30, 2017   \n",
       "5                                         Wiz Khalifa      April 6, 2015   \n",
       "6                          Cocomelon - Nursery Rhymes       May 24, 2018   \n",
       "7               ChuChu TV Nursery Rhymes & Kids Songs      March 6, 2014   \n",
       "8                                         Mark Ronson  November 19, 2014   \n",
       "9                                                 Psy      July 15, 2012   \n",
       "10                                        Miroshka TV  February 27, 2018   \n",
       "11                                      Ultra Records      April 5, 2018   \n",
       "12                                         Get Movies   January 31, 2012   \n",
       "13                                         Crazy Frog      June 16, 2009   \n",
       "14                                           Maroon 5   January 14, 2015   \n",
       "15                         Cocomelon - Nursery Rhymes      June 25, 2018   \n",
       "16                                        OneRepublic       May 31, 2013   \n",
       "17                                       Jingle Toons      June 14, 2018   \n",
       "18                                         Katy Perry  September 5, 2013   \n",
       "19                                            Shakira       June 4, 2010   \n",
       "20                                      Justin Bieber   October 22, 2015   \n",
       "21                              T-Series Bhakti Sagar       May 10, 2011   \n",
       "22      Kiddiestv Hindi - Nursery Rhymes & Kids Songs   January 26, 2018   \n",
       "23                                         Ed Sheeran    October 7, 2014   \n",
       "24                                         Ed Sheeran   November 9, 2017   \n",
       "25                                         Katy Perry  February 20, 2014   \n",
       "26                                          Passenger      July 25, 2012   \n",
       "27                                        Alan Walker   December 3, 2015   \n",
       "28                                           Maroon 5       May 31, 2018   \n",
       "29                               Major Lazer Official     March 22, 2015   \n",
       "\n",
       "   Views (Billions)  \n",
       "0             14.32  \n",
       "1              8.41  \n",
       "2              6.89  \n",
       "3              6.66  \n",
       "4              6.23  \n",
       "5              6.22  \n",
       "6              6.01  \n",
       "7              5.75  \n",
       "8              5.18  \n",
       "9              5.10  \n",
       "10             5.09  \n",
       "11             4.59  \n",
       "12             4.57  \n",
       "13             4.45  \n",
       "14             4.02  \n",
       "15             4.01  \n",
       "16             4.00  \n",
       "17             3.98  \n",
       "18             3.98  \n",
       "19             3.89  \n",
       "20             3.78  \n",
       "21             3.77  \n",
       "22             3.76  \n",
       "23             3.75  \n",
       "24             3.70  \n",
       "25             3.70  \n",
       "26             3.64  \n",
       "27             3.60  \n",
       "28             3.58  \n",
       "29             3.57  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating dataframe\n",
    "import pandas as pd\n",
    "youtube_video_df = pd.DataFrame({'Video Rank':video_rank, 'Name':video_name, 'Artist':video_artist, 'Upload Date':video_upload_date, 'Views (Billions)':video_views})\n",
    "youtube_video_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9f9cc92-49a3-4688-9d2f-9236bc2dfeeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7807d45e-257d-48c1-9cbb-e6119ffc2246",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4b182ef2-8824-4e2c-8a4a-d97d29c7f4f1",
   "metadata": {},
   "source": [
    "Q2. Scrape the details team India’s international fixtures from bcci.tv.\n",
    "\n",
    "Url = https://www.bcci.tv/.\n",
    "\n",
    "You need to find following details:\n",
    "A) Series\n",
    "B) Place\n",
    "C) Date\n",
    "D) Time\n",
    "\n",
    "Note: - From bcci.tv home page you have reach to the international fixture page through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "12c87a8c-a7d0-4fd9-932f-891286369177",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing Selenium, pandas, selenium webdriver, warnings, and time\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import requests\n",
    "import re\n",
    "\n",
    "#importing selenium webdriver\n",
    "from selenium import webdriver\n",
    "\n",
    "#importing warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from time import sleep\n",
    "from selenium.webdriver import ActionChains\n",
    "from selenium.webdriver.common.actions.action_builder import ActionBuilder\n",
    "from selenium.webdriver.common.actions.mouse_button import MouseButton\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "#Importing Exceptions\n",
    "from selenium.common.exceptions import NoSuchElementException as NSEE\n",
    "from selenium.common.exceptions import StaleElementReferenceException as SERE\n",
    "from selenium.common.exceptions import ElementNotInteractableException as ENIE\n",
    "from selenium.common.exceptions import TimeoutException as TE\n",
    "from selenium.common.exceptions import InvalidSelectorException as ISE\n",
    "from selenium.common.exceptions import ElementClickInterceptedException as ECIE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5fdb1005-224b-439d-b64a-49f508ccd884",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping cricket tournaments from bcci website\n",
    "bcci_driver = webdriver.Chrome() #opening automated chrome browser using selenium driver\n",
    "bcci_driver.maximize_window() #maximize window\n",
    "bcci_url =  'https://www.bcci.tv/' #url\n",
    "bcci_driver.get(bcci_url) #opening the webpage on automated chrome browser\n",
    "time.sleep(2) #asking driver to wait for 2 seconds\n",
    "\n",
    "try:\n",
    "    fixtures_menu = bcci_driver.find_element(By.XPATH,'//div[@class=\"w-100 tab-pane fade  show active \"]/ul/div[1]/a[2]')\n",
    "    fixtures_menu.click()\n",
    "except NSEE:\n",
    "    print(\"Exception Raised: \\n\", NSEE)\n",
    "except SERE:\n",
    "    print(\"Exception Raised: \\n\", SERE)\n",
    "except ENIE:\n",
    "    print(\"Exception Raised: \\n\", ENIE)\n",
    "except TE:\n",
    "    print(\"Exception Raised: \\n\", TE)\n",
    "except ISE:\n",
    "    print(\"Exception Raised: \\n\", ISE)\n",
    "except ECIE:\n",
    "    print(\"Exception Raised: \\n\", ECIE)\n",
    "\n",
    "time.sleep(2)\n",
    "\n",
    "#Declaring lists\n",
    "cricket_series = []\n",
    "tournament_place = []\n",
    "tournament_date = []\n",
    "tournament_time = []\n",
    "\n",
    "#scraping for series name from the international fixtures page\n",
    "series = bcci_driver.find_elements(By.XPATH, '//h5[@class=\"match-tournament-name ng-binding\"]')\n",
    "for i in series:\n",
    "    try:\n",
    "        cricket_series.append(i.text)\n",
    "    except NSEE:\n",
    "        cricket_series.append('--')\n",
    "    except SERE:\n",
    "        cricket_series.append('--')\n",
    "    except ENIE:\n",
    "        cricket_series.append('--')\n",
    "    except TE:\n",
    "        cricket_series.append('--')\n",
    "    except ISE:\n",
    "        cricket_series.append('--')\n",
    "    except ECIE:\n",
    "        cricket_series.append('--')\n",
    "\n",
    "\n",
    "#scraping for tournament place from the international fixtures page\n",
    "place = bcci_driver.find_elements(By.XPATH, '//div[@class=\"match-place ng-scope\"]')\n",
    "for i in place:\n",
    "    try:\n",
    "        tournament_place.append(i.text)\n",
    "    except NSEE:\n",
    "        tournament_place.append('--')\n",
    "    except SERE:\n",
    "        tournament_place.append('--')\n",
    "    except ENIE:\n",
    "        tournament_place.append('--')\n",
    "    except TE:\n",
    "        tournament_place.append('--')\n",
    "    except ISE:\n",
    "        tournament_place.append('--')\n",
    "    except ECIE:\n",
    "        tournament_place.append('--')\n",
    "\n",
    "#scraping for tournament date from the international fixtures page\n",
    "t_date = bcci_driver.find_elements(By.XPATH, '//div[@class=\"match-dates ng-binding\"]')\n",
    "for i in t_date:\n",
    "    try:\n",
    "        tournament_date.append(i.text)\n",
    "    except NSEE:\n",
    "        tournament_date.append('--')\n",
    "    except SERE:\n",
    "        tournament_date.append('--')\n",
    "    except ENIE:\n",
    "        tournament_date.append('--')\n",
    "    except TE:\n",
    "        tournament_date.append('--')\n",
    "    except ISE:\n",
    "        tournament_date.append('--')\n",
    "    except ECIE:\n",
    "        tournament_date.append('--')\n",
    "\n",
    "#scraping for tournament time from the international fixtures page\n",
    "t_time = bcci_driver.find_elements(By.XPATH, '//div[@class=\"match-time no-margin ng-binding\"]')\n",
    "for i in t_time:\n",
    "    try:\n",
    "        tournament_time.append(i.text)\n",
    "    except NSEE:\n",
    "        tournament_time.append('--')\n",
    "    except SERE:\n",
    "        tournament_time.append('--')\n",
    "    except ENIE:\n",
    "        tournament_time.append('--')\n",
    "    except TE:\n",
    "        tournament_time.append('--')\n",
    "    except ISE:\n",
    "        tournament_time.append('--')\n",
    "    except ECIE:\n",
    "        tournament_time.append('--')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "727a722a-35f1-4c29-85ad-0fb47f02e996",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 9 9 9\n"
     ]
    }
   ],
   "source": [
    "print(len(cricket_series), len(tournament_place), len(tournament_date), len(tournament_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "77396f0c-f6f3-415e-802c-9a04188a28af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Series Name</th>\n",
       "      <th>Tournament Place</th>\n",
       "      <th>Tournament Date</th>\n",
       "      <th>Tournament Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ICC MENS T20 WORLD CUP 2024</td>\n",
       "      <td>Nassau County International Cricket Stadium, N...</td>\n",
       "      <td>5 JUNE, 2024</td>\n",
       "      <td>8:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ICC MENS T20 WORLD CUP 2024</td>\n",
       "      <td>Nassau County International Cricket Stadium, N...</td>\n",
       "      <td>9 JUNE, 2024</td>\n",
       "      <td>8:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ICC MENS T20 WORLD CUP 2024</td>\n",
       "      <td>Nassau County International Cricket Stadium, N...</td>\n",
       "      <td>12 JUNE, 2024</td>\n",
       "      <td>8:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ICC MENS T20 WORLD CUP 2024</td>\n",
       "      <td>Central Broward Park &amp; Broward County Stadium,...</td>\n",
       "      <td>15 JUNE, 2024</td>\n",
       "      <td>8:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>INDIA TOUR OF ZIMBABWE 2024</td>\n",
       "      <td>Harare Sports Club, Harare</td>\n",
       "      <td>6 JULY, 2024</td>\n",
       "      <td>8:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>INDIA TOUR OF ZIMBABWE 2024</td>\n",
       "      <td>Harare Sports Club, Harare</td>\n",
       "      <td>7 JULY, 2024</td>\n",
       "      <td>8:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>INDIA TOUR OF ZIMBABWE 2024</td>\n",
       "      <td>Harare Sports Club, Harare</td>\n",
       "      <td>10 JULY, 2024</td>\n",
       "      <td>8:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>INDIA TOUR OF ZIMBABWE 2024</td>\n",
       "      <td>Harare Sports Club, Harare</td>\n",
       "      <td>13 JULY, 2024</td>\n",
       "      <td>8:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>INDIA TOUR OF ZIMBABWE 2024</td>\n",
       "      <td>Harare Sports Club, Harare</td>\n",
       "      <td>14 JULY, 2024</td>\n",
       "      <td>8:00 PM IST</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Series Name  \\\n",
       "0  ICC MENS T20 WORLD CUP 2024   \n",
       "1  ICC MENS T20 WORLD CUP 2024   \n",
       "2  ICC MENS T20 WORLD CUP 2024   \n",
       "3  ICC MENS T20 WORLD CUP 2024   \n",
       "4  INDIA TOUR OF ZIMBABWE 2024   \n",
       "5  INDIA TOUR OF ZIMBABWE 2024   \n",
       "6  INDIA TOUR OF ZIMBABWE 2024   \n",
       "7  INDIA TOUR OF ZIMBABWE 2024   \n",
       "8  INDIA TOUR OF ZIMBABWE 2024   \n",
       "\n",
       "                                    Tournament Place Tournament Date  \\\n",
       "0  Nassau County International Cricket Stadium, N...    5 JUNE, 2024   \n",
       "1  Nassau County International Cricket Stadium, N...    9 JUNE, 2024   \n",
       "2  Nassau County International Cricket Stadium, N...   12 JUNE, 2024   \n",
       "3  Central Broward Park & Broward County Stadium,...   15 JUNE, 2024   \n",
       "4                         Harare Sports Club, Harare    6 JULY, 2024   \n",
       "5                         Harare Sports Club, Harare    7 JULY, 2024   \n",
       "6                         Harare Sports Club, Harare   10 JULY, 2024   \n",
       "7                         Harare Sports Club, Harare   13 JULY, 2024   \n",
       "8                         Harare Sports Club, Harare   14 JULY, 2024   \n",
       "\n",
       "  Tournament Time  \n",
       "0     8:00 PM IST  \n",
       "1     8:00 PM IST  \n",
       "2     8:00 PM IST  \n",
       "3     8:00 PM IST  \n",
       "4     8:00 PM IST  \n",
       "5     8:00 PM IST  \n",
       "6     8:00 PM IST  \n",
       "7     8:00 PM IST  \n",
       "8     8:00 PM IST  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating dataframe\n",
    "import pandas as pd\n",
    "cricket_df = pd.DataFrame({'Series Name':cricket_series, 'Tournament Place':tournament_place, 'Tournament Date':tournament_date, 'Tournament Time':tournament_time})\n",
    "cricket_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d3929822-5de6-4119-97b9-c7f8a1606e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "bcci_driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "707d3db5-5ad5-45d5-9e27-f32c6cacef94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6f93abbd-9f40-4d10-8332-aca7f29261dc",
   "metadata": {},
   "source": [
    "Q3. Scrape the details of State-wise GDP of India from statisticstime.com.\n",
    "\n",
    "Url = http://statisticstimes.com/\n",
    "\n",
    "You have to find following details: \n",
    "A) Rank\n",
    "B) State\n",
    "C) GSDP(21-22)- at current prices\n",
    "D) GSDP(22-23)- at current prices\n",
    "E) Share(21-22)\n",
    "F) GDP($ billion)\n",
    "\n",
    "Note: - From statisticstimes home page you have to reach to economy page through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a4ea8b2d-f5c3-4321-bb75-e0dfb7cf5340",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing Selenium, pandas, selenium webdriver, warnings, and time\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import requests\n",
    "import re\n",
    "\n",
    "#importing selenium webdriver\n",
    "from selenium import webdriver\n",
    "\n",
    "#importing warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from time import sleep\n",
    "from selenium.webdriver import ActionChains\n",
    "from selenium.webdriver.common.actions.action_builder import ActionBuilder\n",
    "from selenium.webdriver.common.actions.mouse_button import MouseButton\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "#Importing Exceptions\n",
    "from selenium.common.exceptions import NoSuchElementException as NSEE\n",
    "from selenium.common.exceptions import StaleElementReferenceException as SERE\n",
    "from selenium.common.exceptions import ElementNotInteractableException as ENIE\n",
    "from selenium.common.exceptions import TimeoutException as TE\n",
    "from selenium.common.exceptions import InvalidSelectorException as ISE\n",
    "from selenium.common.exceptions import ElementClickInterceptedException as ECIE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "60f16a9c-ee8e-4221-a2e8-ad226407b189",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping details of GDP of Indian states \n",
    "gdp_driver = webdriver.Chrome() #opening automated chrome browser using selenium driver\n",
    "gdp_driver.maximize_window() #maximize window\n",
    "gdp_url =  'http://statisticstimes.com/' #url\n",
    "gdp_driver.get(gdp_url) #opening the webpage on automated chrome browser\n",
    "time.sleep(5) #asking driver to wait for 5 seconds\n",
    "\n",
    "#navigating to the required page\n",
    "try:\n",
    "    economy_menu = gdp_driver.find_element(By.XPATH,'//div[@class=\"navbar\"]/div[2]/button')\n",
    "    economy_menu.click()\n",
    "    time.sleep(2)\n",
    "    sub_menu = gdp_driver.find_element(By.XPATH, '//div[@class=\"navbar\"]/div[2]/div/a[3]')\n",
    "    sub_menu.click()\n",
    "except NSEE:\n",
    "    print(\"Exception Raised: \\n\", NSEE)\n",
    "except SERE:\n",
    "    print(\"Exception Raised: \\n\", SERE)\n",
    "except ENIE:\n",
    "    print(\"Exception Raised: \\n\", ENIE)\n",
    "except TE:\n",
    "    print(\"Exception Raised: \\n\", TE)\n",
    "except ISE:\n",
    "    print(\"Exception Raised: \\n\", ISE)\n",
    "except ECIE:\n",
    "    print(\"Exception Raised: \\n\", ECIE)\n",
    "\n",
    "time.sleep(2)\n",
    "\n",
    "try:\n",
    "    gdp_driver.get('https://statisticstimes.com/economy/india-statistics.php')\n",
    "    state_gdp_link = gdp_driver.find_element(By.XPATH, '/html/body/div[2]/div[2]/div[2]/ul/li[1]/a')\n",
    "    state_gdp_link.click()\n",
    "except NSEE:\n",
    "    print(\"Exception Raised: \\n\", NSEE)\n",
    "except SERE:\n",
    "    print(\"Exception Raised: \\n\", SERE)\n",
    "except ENIE:\n",
    "    print(\"Exception Raised: \\n\", ENIE)\n",
    "except TE:\n",
    "    print(\"Exception Raised: \\n\", TE)\n",
    "except ISE:\n",
    "    print(\"Exception Raised: \\n\", ISE)\n",
    "except ECIE:\n",
    "    print(\"Exception Raised: \\n\", ECIE)\n",
    "\n",
    "time.sleep(5)\n",
    "\n",
    "#Declaring lists\n",
    "\n",
    "gdp_rank = []\n",
    "state_name = []\n",
    "previous_gsdp = []\n",
    "present_gsdp = []\n",
    "state_share = []\n",
    "state_gdp = []\n",
    "\n",
    "#scraping for gdp rank \n",
    "rank = gdp_driver.find_elements(By.XPATH, '//div[@id=\"main\"]/div[5]/div[1]/div/table/tbody/tr/td[1]')\n",
    "for i in rank:\n",
    "    try:\n",
    "        gdp_rank.append(i.text)\n",
    "    except NSEE:\n",
    "        gdp_rank.append('--')\n",
    "    except SERE:\n",
    "        gdp_rank.append('--')\n",
    "    except ENIE:\n",
    "        gdp_rank.append('--')\n",
    "    except TE:\n",
    "        gdp_rank.append('--')\n",
    "    except ISE:\n",
    "        gdp_rank.append('--')\n",
    "    except ECIE:\n",
    "        gdp_rank.append('--')\n",
    "\n",
    "#scraping for name of the state\n",
    "name = gdp_driver.find_elements(By.XPATH, '//div[@id=\"main\"]/div[5]/div[1]/div/table/tbody/tr/td[2]')\n",
    "for i in name:\n",
    "    try:\n",
    "        state_name.append(i.text)\n",
    "    except NSEE:\n",
    "        state_name.append('--')\n",
    "    except SERE:\n",
    "        state_name.append('--')\n",
    "    except ENIE:\n",
    "        state_name.append('--')\n",
    "    except TE:\n",
    "        state_name.append('--')\n",
    "    except ISE:\n",
    "        state_name.append('--')\n",
    "    except ECIE:\n",
    "        state_name.append('--')\n",
    "\n",
    "#scraping for GSDP(21-22)- at current prices\n",
    "gdp_past = gdp_driver.find_elements(By.XPATH, '//div[@id=\"main\"]/div[5]/div[1]/div/table/tbody/tr/td[5]')\n",
    "for i in gdp_past:\n",
    "    try:\n",
    "        previous_gsdp.append(i.text)\n",
    "    except NSEE:\n",
    "        previous_gsdp.append('--')\n",
    "    except SERE:\n",
    "        previous_gsdp.append('--')\n",
    "    except ENIE:\n",
    "        previous_gsdp.append('--')\n",
    "    except TE:\n",
    "        previous_gsdp.append('--')\n",
    "    except ISE:\n",
    "        previous_gsdp.append('--')\n",
    "    except ECIE:\n",
    "        previous_gsdp.append('--')\n",
    "\n",
    "#scraping for GSDP(22-23)- at current prices\n",
    "gdp_now = gdp_driver.find_elements(By.XPATH, '//div[@id=\"main\"]/div[5]/div[1]/div/table/tbody/tr/td[4]')\n",
    "for i in gdp_now:\n",
    "    try:\n",
    "        present_gsdp.append(i.text)\n",
    "    except NSEE:\n",
    "        present_gsdp.append('--')\n",
    "    except SERE:\n",
    "        present_gsdp.append('--')\n",
    "    except ENIE:\n",
    "        present_gsdp.append('--')\n",
    "    except TE:\n",
    "        present_gsdp.append('--')\n",
    "    except ISE:\n",
    "        present_gsdp.append('--')\n",
    "    except ECIE:\n",
    "        present_gsdp.append('--')\n",
    "\n",
    "#scraping for Share(21-22)\n",
    "share = gdp_driver.find_elements(By.XPATH, '//div[@id=\"main\"]/div[5]/div[1]/div/table/tbody/tr/td[6]')\n",
    "for i in share:\n",
    "    try:\n",
    "        state_share.append(i.text)\n",
    "    except NSEE:\n",
    "        state_share.append('--')\n",
    "    except SERE:\n",
    "        state_share.append('--')\n",
    "    except ENIE:\n",
    "        state_share.append('--')\n",
    "    except TE:\n",
    "        state_share.append('--')\n",
    "    except ISE:\n",
    "        state_share.append('--')\n",
    "    except ECIE:\n",
    "        state_share.append('--')\n",
    "\n",
    "#scraping for GDP($ billion)\n",
    "gdp = gdp_driver.find_elements(By.XPATH, '//div[@id=\"main\"]/div[5]/div[1]/div/table/tbody/tr/td[7]')\n",
    "for i in gdp:\n",
    "    try:\n",
    "        state_gdp.append(i.text)\n",
    "    except NSEE:\n",
    "        state_gdp.append('--')\n",
    "    except SERE:\n",
    "        state_gdp.append('--')\n",
    "    except ENIE:\n",
    "        state_gdp.append('--')\n",
    "    except TE:\n",
    "        state_gdp.append('--')\n",
    "    except ISE:\n",
    "        state_gdp.append('--')\n",
    "    except ECIE:\n",
    "        state_gdp.append('--')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ab26e5c0-914f-47e0-9593-02a04295ea1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33 33 33 33 33 33\n"
     ]
    }
   ],
   "source": [
    "print(len(gdp_rank), len(state_name), len(previous_gsdp), len(present_gsdp), len(state_share), len(state_gdp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5da09e80-2702-4861-ace8-9c5665719bb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State Rank</th>\n",
       "      <th>State</th>\n",
       "      <th>GSDP(21-22)- at current prices</th>\n",
       "      <th>GSDP(22-23)- at current prices</th>\n",
       "      <th>Share(21-22)</th>\n",
       "      <th>State GDP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>3,108,022</td>\n",
       "      <td>-</td>\n",
       "      <td>13.17%</td>\n",
       "      <td>414.928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Tamil Nadu</td>\n",
       "      <td>2,071,286</td>\n",
       "      <td>2,364,514</td>\n",
       "      <td>8.78%</td>\n",
       "      <td>276.522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Karnataka</td>\n",
       "      <td>1,978,094</td>\n",
       "      <td>2,269,995</td>\n",
       "      <td>8.38%</td>\n",
       "      <td>264.080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Uttar Pradesh</td>\n",
       "      <td>1,975,595</td>\n",
       "      <td>2,258,040</td>\n",
       "      <td>8.37%</td>\n",
       "      <td>263.747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Gujarat</td>\n",
       "      <td>1,928,683</td>\n",
       "      <td>2,230,609</td>\n",
       "      <td>8.17%</td>\n",
       "      <td>257.484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>West Bengal</td>\n",
       "      <td>1,329,238</td>\n",
       "      <td>1,531,758</td>\n",
       "      <td>5.63%</td>\n",
       "      <td>177.456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Rajasthan</td>\n",
       "      <td>1,193,489</td>\n",
       "      <td>1,365,849</td>\n",
       "      <td>5.06%</td>\n",
       "      <td>159.334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Andhra Pradesh</td>\n",
       "      <td>1,148,471</td>\n",
       "      <td>1,303,524</td>\n",
       "      <td>4.87%</td>\n",
       "      <td>153.324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Telangana</td>\n",
       "      <td>1,124,204</td>\n",
       "      <td>1,308,034</td>\n",
       "      <td>4.76%</td>\n",
       "      <td>150.084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Madhya Pradesh</td>\n",
       "      <td>1,092,964</td>\n",
       "      <td>1,246,471</td>\n",
       "      <td>4.63%</td>\n",
       "      <td>145.913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>Kerala</td>\n",
       "      <td>934,542</td>\n",
       "      <td>1,046,188</td>\n",
       "      <td>3.96%</td>\n",
       "      <td>124.764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>881,336</td>\n",
       "      <td>1,014,688</td>\n",
       "      <td>3.73%</td>\n",
       "      <td>117.660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>Haryana</td>\n",
       "      <td>868,905</td>\n",
       "      <td>984,055</td>\n",
       "      <td>3.68%</td>\n",
       "      <td>116.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>Odisha</td>\n",
       "      <td>662,886</td>\n",
       "      <td>753,177</td>\n",
       "      <td>2.81%</td>\n",
       "      <td>88.497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>Bihar</td>\n",
       "      <td>650,302</td>\n",
       "      <td>751,396</td>\n",
       "      <td>2.76%</td>\n",
       "      <td>86.817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>Punjab</td>\n",
       "      <td>617,192</td>\n",
       "      <td>676,164</td>\n",
       "      <td>2.62%</td>\n",
       "      <td>82.397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>Assam</td>\n",
       "      <td>411,454</td>\n",
       "      <td>493,167</td>\n",
       "      <td>1.74%</td>\n",
       "      <td>54.930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>Chhattisgarh</td>\n",
       "      <td>410,525</td>\n",
       "      <td>464,399</td>\n",
       "      <td>1.74%</td>\n",
       "      <td>54.806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>Jharkhand</td>\n",
       "      <td>358,863</td>\n",
       "      <td>393,722</td>\n",
       "      <td>1.52%</td>\n",
       "      <td>47.909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>Uttarakhand</td>\n",
       "      <td>267,143</td>\n",
       "      <td>303,781</td>\n",
       "      <td>1.13%</td>\n",
       "      <td>35.664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>Jammu &amp; Kashmir</td>\n",
       "      <td>193,352</td>\n",
       "      <td>224,226</td>\n",
       "      <td>0.82%</td>\n",
       "      <td>25.813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>Himachal Pradesh</td>\n",
       "      <td>172,162</td>\n",
       "      <td>191,728</td>\n",
       "      <td>0.73%</td>\n",
       "      <td>22.984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>Goa</td>\n",
       "      <td>84,266</td>\n",
       "      <td>93,672</td>\n",
       "      <td>0.36%</td>\n",
       "      <td>11.250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>Tripura</td>\n",
       "      <td>62,550</td>\n",
       "      <td>72,636</td>\n",
       "      <td>0.27%</td>\n",
       "      <td>8.351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>Chandigarh</td>\n",
       "      <td>46,096</td>\n",
       "      <td>54,285</td>\n",
       "      <td>0.20%</td>\n",
       "      <td>6.154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>Puducherry</td>\n",
       "      <td>43,810</td>\n",
       "      <td>49,643</td>\n",
       "      <td>0.19%</td>\n",
       "      <td>5.849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>Meghalaya</td>\n",
       "      <td>38,785</td>\n",
       "      <td>42,697</td>\n",
       "      <td>0.16%</td>\n",
       "      <td>5.178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>Sikkim</td>\n",
       "      <td>37,557</td>\n",
       "      <td>42,756</td>\n",
       "      <td>0.16%</td>\n",
       "      <td>5.014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>Manipur</td>\n",
       "      <td>36,594</td>\n",
       "      <td>-</td>\n",
       "      <td>0.16%</td>\n",
       "      <td>4.885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>Arunachal Pradesh</td>\n",
       "      <td>34,775</td>\n",
       "      <td>39,630</td>\n",
       "      <td>0.15%</td>\n",
       "      <td>4.643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>31</td>\n",
       "      <td>Nagaland</td>\n",
       "      <td>31,038</td>\n",
       "      <td>35,643</td>\n",
       "      <td>0.13%</td>\n",
       "      <td>4.144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>32</td>\n",
       "      <td>Mizoram</td>\n",
       "      <td>27,824</td>\n",
       "      <td>-</td>\n",
       "      <td>0.12%</td>\n",
       "      <td>3.715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>33</td>\n",
       "      <td>Andaman &amp; Nicobar Islands</td>\n",
       "      <td>10,371</td>\n",
       "      <td>-</td>\n",
       "      <td>0.04%</td>\n",
       "      <td>1.385</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   State Rank                      State GSDP(21-22)- at current prices  \\\n",
       "0           1                Maharashtra                      3,108,022   \n",
       "1           2                 Tamil Nadu                      2,071,286   \n",
       "2           3                  Karnataka                      1,978,094   \n",
       "3           4              Uttar Pradesh                      1,975,595   \n",
       "4           5                    Gujarat                      1,928,683   \n",
       "5           6                West Bengal                      1,329,238   \n",
       "6           7                  Rajasthan                      1,193,489   \n",
       "7           8             Andhra Pradesh                      1,148,471   \n",
       "8           9                  Telangana                      1,124,204   \n",
       "9          10             Madhya Pradesh                      1,092,964   \n",
       "10         11                     Kerala                        934,542   \n",
       "11         12                      Delhi                        881,336   \n",
       "12         13                    Haryana                        868,905   \n",
       "13         14                     Odisha                        662,886   \n",
       "14         15                      Bihar                        650,302   \n",
       "15         16                     Punjab                        617,192   \n",
       "16         17                      Assam                        411,454   \n",
       "17         18               Chhattisgarh                        410,525   \n",
       "18         19                  Jharkhand                        358,863   \n",
       "19         20                Uttarakhand                        267,143   \n",
       "20         21            Jammu & Kashmir                        193,352   \n",
       "21         22           Himachal Pradesh                        172,162   \n",
       "22         23                        Goa                         84,266   \n",
       "23         24                    Tripura                         62,550   \n",
       "24         25                 Chandigarh                         46,096   \n",
       "25         26                 Puducherry                         43,810   \n",
       "26         27                  Meghalaya                         38,785   \n",
       "27         28                     Sikkim                         37,557   \n",
       "28         29                    Manipur                         36,594   \n",
       "29         30          Arunachal Pradesh                         34,775   \n",
       "30         31                   Nagaland                         31,038   \n",
       "31         32                    Mizoram                         27,824   \n",
       "32         33  Andaman & Nicobar Islands                         10,371   \n",
       "\n",
       "   GSDP(22-23)- at current prices Share(21-22) State GDP  \n",
       "0                               -       13.17%   414.928  \n",
       "1                       2,364,514        8.78%   276.522  \n",
       "2                       2,269,995        8.38%   264.080  \n",
       "3                       2,258,040        8.37%   263.747  \n",
       "4                       2,230,609        8.17%   257.484  \n",
       "5                       1,531,758        5.63%   177.456  \n",
       "6                       1,365,849        5.06%   159.334  \n",
       "7                       1,303,524        4.87%   153.324  \n",
       "8                       1,308,034        4.76%   150.084  \n",
       "9                       1,246,471        4.63%   145.913  \n",
       "10                      1,046,188        3.96%   124.764  \n",
       "11                      1,014,688        3.73%   117.660  \n",
       "12                        984,055        3.68%   116.001  \n",
       "13                        753,177        2.81%    88.497  \n",
       "14                        751,396        2.76%    86.817  \n",
       "15                        676,164        2.62%    82.397  \n",
       "16                        493,167        1.74%    54.930  \n",
       "17                        464,399        1.74%    54.806  \n",
       "18                        393,722        1.52%    47.909  \n",
       "19                        303,781        1.13%    35.664  \n",
       "20                        224,226        0.82%    25.813  \n",
       "21                        191,728        0.73%    22.984  \n",
       "22                         93,672        0.36%    11.250  \n",
       "23                         72,636        0.27%     8.351  \n",
       "24                         54,285        0.20%     6.154  \n",
       "25                         49,643        0.19%     5.849  \n",
       "26                         42,697        0.16%     5.178  \n",
       "27                         42,756        0.16%     5.014  \n",
       "28                              -        0.16%     4.885  \n",
       "29                         39,630        0.15%     4.643  \n",
       "30                         35,643        0.13%     4.144  \n",
       "31                              -        0.12%     3.715  \n",
       "32                              -        0.04%     1.385  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating dataframe\n",
    "import pandas as pd\n",
    "gdp_df = pd.DataFrame({'State Rank':gdp_rank, 'State':state_name, 'GSDP(21-22)- at current prices':previous_gsdp, 'GSDP(22-23)- at current prices':present_gsdp, 'Share(21-22)':state_share, 'State GDP':state_gdp})\n",
    "gdp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8df8fe23-4e19-4473-8ca7-53735826500e",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdp_driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e13a23fa-88e4-4fa6-9eee-5563c4cad0c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "34140ee2-9229-479a-bf6b-2c3d5c219d7c",
   "metadata": {},
   "source": [
    "Q4. Scrape the details of trending repositories on Github.com.\n",
    "\n",
    "Url = https://github.com/\n",
    "\n",
    "You have to find the following details:\n",
    "\n",
    "A) Repository title\n",
    "B) Repository description\n",
    "C) Contributors count\n",
    "D) Language used\n",
    "\n",
    "Note: - From the home page you have to click on the trending option from Explore menu through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e9498d8b-c873-4d55-b5b6-c1ab6affcc92",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing Selenium, pandas, selenium webdriver, warnings, and time\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import requests\n",
    "import re\n",
    "\n",
    "#importing selenium webdriver\n",
    "from selenium import webdriver\n",
    "\n",
    "#importing warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from time import sleep\n",
    "from selenium.webdriver import ActionChains\n",
    "from selenium.webdriver.common.actions.action_builder import ActionBuilder\n",
    "from selenium.webdriver.common.actions.mouse_button import MouseButton\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "#Importing Exceptions\n",
    "from selenium.common.exceptions import NoSuchElementException as NSEE\n",
    "from selenium.common.exceptions import StaleElementReferenceException as SERE\n",
    "from selenium.common.exceptions import ElementNotInteractableException as ENIE\n",
    "from selenium.common.exceptions import TimeoutException as TE\n",
    "from selenium.common.exceptions import InvalidSelectorException as ISE\n",
    "from selenium.common.exceptions import ElementClickInterceptedException as ECIE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8db7ebf3-1d5a-4f4f-9750-1d45eaa845ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "github_driver = webdriver.Chrome() #opening automated chrome browser using selenium driver\n",
    "github_driver.maximize_window() #maximize window\n",
    "github_url =  'https://github.com/' #url\n",
    "github_driver.get(github_url) #opening the webpage on automated chrome browser\n",
    "time.sleep(2) #asking driver to wait for 2 seconds\n",
    "\n",
    "#navigating to the required page\n",
    "try:\n",
    "    main_menu = github_driver.find_element(By.XPATH,'//nav[@class=\"mt-0 px-3 px-lg-0 mb-3 mb-lg-0\"]/ul/li[3]/button')\n",
    "    main_menu.click()\n",
    "    time.sleep(2)\n",
    "    sub_menu = github_driver.find_element(By.XPATH, '//nav[@class=\"mt-0 px-3 px-lg-0 mb-3 mb-lg-0\"]/ul/li[3]/div/div[3]/ul/li[2]')\n",
    "    sub_menu.click()\n",
    "except NSEE:\n",
    "    print(\"Exception Raised: \\n\", NSEE)\n",
    "except SERE:\n",
    "    print(\"Exception Raised: \\n\", SERE)\n",
    "except ENIE:\n",
    "    print(\"Exception Raised: \\n\", ENIE)\n",
    "except TE:\n",
    "    print(\"Exception Raised: \\n\", TE)\n",
    "except ISE:\n",
    "    print(\"Exception Raised: \\n\", ISE)\n",
    "except ECIE:\n",
    "    print(\"Exception Raised: \\n\", ECIE)\n",
    "\n",
    "time.sleep(2)\n",
    "\n",
    "#scraping for repository title\n",
    "repository_title = []\n",
    "title = github_driver.find_elements(By.XPATH, '//h2[@class=\"h3 lh-condensed\"]')\n",
    "for i in title:\n",
    "    try:\n",
    "        repository_title.append(i.text)\n",
    "    except NSEE:\n",
    "        repository_title.append('--')\n",
    "    except SERE:\n",
    "        repository_title.append('--')\n",
    "    except ENIE:\n",
    "        repository_title.append('--')\n",
    "    except TE:\n",
    "        repository_title.append('--')\n",
    "    except ISE:\n",
    "        repository_title.append('--')\n",
    "    except ECIE:\n",
    "        repository_title.append('--')\n",
    "\n",
    "\n",
    "#scraping for trending repository urls\n",
    "repository_url = []\n",
    "url = github_driver.find_elements(By.XPATH, '//h2[@class=\"h3 lh-condensed\"]/a')\n",
    "for i in url:\n",
    "    try:\n",
    "        repository_url.append(i.get_attribute('href'))\n",
    "    except NSEE:\n",
    "        repository_url.append('--')\n",
    "    except SERE:\n",
    "        repository_url.append('--')\n",
    "    except ENIE:\n",
    "        repository_url.append('--')\n",
    "    except TE:\n",
    "        repository_url.append('--')\n",
    "    except ISE:\n",
    "        repository_url.append('--')\n",
    "    except ECIE:\n",
    "        repository_url.append('--')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9b0ec0a4-b8e6-4c45-95e9-1e084a465c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Declaring lists\n",
    "repository_description = []\n",
    "contributors_count = []\n",
    "language_used = []\n",
    "\n",
    " #iterating each and every url to fetch all repository details \n",
    "for k in repository_url:\n",
    "    github_driver.get(k)\n",
    "    time.sleep(2)\n",
    "    \n",
    "    #scraping for repository description\n",
    "    try:\n",
    "        description = github_driver.find_element(By.XPATH, '//p[@class=\"f4 my-3\"]')\n",
    "        repository_description.append(description.text)\n",
    "    except NSEE:\n",
    "        try:\n",
    "            no_description = github_driver.find_element(By.XPATH, '//div[@class=\"f4 my-3 color-fg-muted text-italic\"]')\n",
    "            repository_description.append(no_description.text)\n",
    "        except NSEE:\n",
    "            repository_description.append('No description Found!')\n",
    "    except SERE:\n",
    "        repository_description.append('--')\n",
    "    except ENIE:\n",
    "        repository_description.append('--')\n",
    "    except TE:\n",
    "        repository_description.append('--')\n",
    "    except ISE:\n",
    "        repository_description.append('--')\n",
    "    except ECIE:\n",
    "        repository_description.append('--')\n",
    "\n",
    "    #scraping for repository contributors count\n",
    "    try:\n",
    "        contributors = github_driver.find_element(By.XPATH, '//div[@class=\"BorderGrid about-margin\"]/div[6]/div/h2/a/span')\n",
    "        if contributors.text == '':\n",
    "            contributors_count.append('No Contributors found!')\n",
    "        else:\n",
    "            contributors_count.append(contributors.text)\n",
    "    except NSEE:\n",
    "        try:\n",
    "            contributors_1 = github_driver.find_element(By.XPATH, '//div[@class=\"BorderGrid about-margin\"]/div[5]/div/h2/a/span')\n",
    "            if contributors_1.text == '':\n",
    "                contributors_count.append(\"No Contributors found!\")\n",
    "            else:\n",
    "                contributors_count.append(contributors_1.text)\n",
    "        except NSEE:\n",
    "            try:\n",
    "                contributors_2 = github_driver.find_element(By.XPATH, '//div[@class=\"BorderGrid about-margin\"]/div[4]/div/h2/a/span')\n",
    "                if contributors_2.text == '':\n",
    "                    contributors_count.append(\"No Contributors found!\")\n",
    "                else:\n",
    "                    contributors_count.append(contributors_2.text)\n",
    "            except NSEE:\n",
    "                try:\n",
    "                    contributors_3 = github_driver.find_element(By.XPATH, '//div[@class=\"BorderGrid about-margin\"]/div[3]/div/h2/a/span')\n",
    "                    if contributors_3.text == '':\n",
    "                        contributors_count.append(\"No Contributors found!\")\n",
    "                    else:\n",
    "                        contributors_count.append(contributors_3.text)\n",
    "                except NSEE:\n",
    "                    contributors_count.append(\"No Contributors found!\")\n",
    "    except SERE:\n",
    "        contributors_count.append('--')\n",
    "    except ENIE:\n",
    "        contributors_count.append('--')\n",
    "    except TE:\n",
    "        contributors_count.append('--')\n",
    "    except ISE:\n",
    "        contributors_count.append('--')\n",
    "    except ECIE:\n",
    "        contributors_count.append('--')\n",
    "\n",
    "    #scraping for trending repository language used\n",
    "    try:\n",
    "        language = github_driver.find_element(By.XPATH, '//div[@class=\"BorderGrid about-margin\"]/div[7]/div/ul')\n",
    "        if language.text == '':\n",
    "            language_used.append('No language usage found!')\n",
    "        else:\n",
    "            language_used.append(language.text.replace('\\n',' '))\n",
    "    except NSEE:\n",
    "        try:\n",
    "            language_1 = github_driver.find_element(By.XPATH, '//div[@class=\"BorderGrid about-margin\"]/div[6]/div/ul')\n",
    "            if contributors_1.text == '':\n",
    "                language_used.append(\"No language usage found!\")\n",
    "            else:\n",
    "                language_used.append(language_1.text.replace('\\n',' '))\n",
    "        except NSEE:\n",
    "            try:\n",
    "                language_2 = github_driver.find_element(By.XPATH, '//div[@class=\"BorderGrid about-margin\"]/div[5]/div/ul')\n",
    "                if language_2.text == '':\n",
    "                    language_used.append(\"No language usage found!\")\n",
    "                else:\n",
    "                    language_used.append(language_2.text.replace('\\n',' '))\n",
    "            except NSEE:\n",
    "                try:\n",
    "                    language_3 = github_driver.find_element(By.XPATH, '//div[@class=\"BorderGrid about-margin\"]/div[4]/div/ul')\n",
    "                    if language_3.text == '':\n",
    "                        language_used.append(\"No language usage found!\")\n",
    "                    else:\n",
    "                        language_used.append(language_3.text.replace('\\n',' '))\n",
    "                except NSEE:\n",
    "                    language_used.append(\"No language usage found!\")\n",
    "    except SERE:\n",
    "        contributors_count.append('--')\n",
    "    except ENIE:\n",
    "        contributors_count.append('--')\n",
    "    except TE:\n",
    "        contributors_count.append('--')\n",
    "    except ISE:\n",
    "        contributors_count.append('--')\n",
    "    except ECIE:\n",
    "        contributors_count.append('--')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "316bf458-a106-4b8f-91b7-0fbb9344dae5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 25 25 25 25\n"
     ]
    }
   ],
   "source": [
    "print(len(repository_url), len(repository_title), len(repository_description), len(contributors_count), len(language_used))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d68eafbb-d221-4291-b786-ea6fad1f6d73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Repository Title</th>\n",
       "      <th>Repository Description</th>\n",
       "      <th>Contributors Count</th>\n",
       "      <th>Language Used</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HardhatChad / ore-cli</td>\n",
       "      <td>No description, website, or topics provided.</td>\n",
       "      <td>4</td>\n",
       "      <td>Rust 100.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>plandex-ai / plandex</td>\n",
       "      <td>An AI coding engine for complex tasks</td>\n",
       "      <td>7</td>\n",
       "      <td>Go 97.4% Shell 1.3% Other 1.3%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>anthropics / anthropic-cookbook</td>\n",
       "      <td>A collection of notebooks/recipes showcasing s...</td>\n",
       "      <td>12</td>\n",
       "      <td>Jupyter Notebook 100.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HardhatChad / ore</td>\n",
       "      <td>No description, website, or topics provided.</td>\n",
       "      <td>No Contributors found!</td>\n",
       "      <td>Rust 100.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ixartz / SaaS-Boilerplate</td>\n",
       "      <td>🚀🎉📚 SaaS Boilerplate built with Next.js + Tail...</td>\n",
       "      <td>4</td>\n",
       "      <td>TypeScript 93.3% JavaScript 4.8% CSS 1.7% Shel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AstroNvim / AstroNvim</td>\n",
       "      <td>AstroNvim is an aesthetic and feature-rich neo...</td>\n",
       "      <td>79</td>\n",
       "      <td>Lua 100.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>availproject / availup</td>\n",
       "      <td>No description, website, or topics provided.</td>\n",
       "      <td>3</td>\n",
       "      <td>Shell 100.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>nilsherzig / LLocalSearch</td>\n",
       "      <td>LLocalSearch is a completely locally running s...</td>\n",
       "      <td>6</td>\n",
       "      <td>Go 49.7% Svelte 40.4% TypeScript 2.8% Makefile...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>FoundationVision / VAR</td>\n",
       "      <td>[GPT beats diffusion🔥] [scaling laws in visual...</td>\n",
       "      <td>2</td>\n",
       "      <td>Python 93.7% Jupyter Notebook 6.3%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>firebase / firebase-ios-sdk</td>\n",
       "      <td>Firebase SDK for Apple App Development</td>\n",
       "      <td>221</td>\n",
       "      <td>Objective-C 44.3% C++ 37.3% Swift 10.2% Object...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>bradtraversy / 50projects50days</td>\n",
       "      <td>50+ mini web projects using HTML, CSS &amp; JS</td>\n",
       "      <td>38</td>\n",
       "      <td>CSS 38.5% HTML 31.6% JavaScript 29.9%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>princeton-nlp / SWE-agent</td>\n",
       "      <td>SWE-agent takes a GitHub issue and tries to au...</td>\n",
       "      <td>14</td>\n",
       "      <td>Python 77.9% Shell 16.1% CSS 2.8% JavaScript 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>PKUFlyingPig / cs-self-learning</td>\n",
       "      <td>计算机自学指南</td>\n",
       "      <td>120</td>\n",
       "      <td>HTML 100.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>searxng / searxng</td>\n",
       "      <td>SearXNG is a free internet metasearch engine w...</td>\n",
       "      <td>220</td>\n",
       "      <td>Python 74.0% Shell 10.2% HTML 6.3% Less 5.0% J...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ossu / computer-science</td>\n",
       "      <td>🎓 Path to a free self-taught education in Comp...</td>\n",
       "      <td>140</td>\n",
       "      <td>No language usage found!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ryanmcdermott / clean-code-javascript</td>\n",
       "      <td>🛁 Clean Code concepts adapted for JavaScript</td>\n",
       "      <td>112</td>\n",
       "      <td>JavaScript 100.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>avito-tech / backend-trainee-assignment-2024</td>\n",
       "      <td>No description, website, or topics provided.</td>\n",
       "      <td>No Contributors found!</td>\n",
       "      <td>No language usage found!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>dockur / windows</td>\n",
       "      <td>Windows in a Docker container.</td>\n",
       "      <td>4</td>\n",
       "      <td>Shell 98.3% Dockerfile 1.7%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>awesome-selfhosted / awesome-selfhosted</td>\n",
       "      <td>A list of Free Software network services and w...</td>\n",
       "      <td>1,260</td>\n",
       "      <td>No language usage found!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>wandb / openui</td>\n",
       "      <td>OpenUI let's you describe UI using your imagin...</td>\n",
       "      <td>7</td>\n",
       "      <td>TypeScript 59.2% Python 33.3% HTML 5.2% CSS 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>mahmoud / awesome-python-applications</td>\n",
       "      <td>💿 Free software that works great, and also hap...</td>\n",
       "      <td>33</td>\n",
       "      <td>Jupyter Notebook 100.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>HerbertHe / iptv-sources</td>\n",
       "      <td>Autoupdate iptv sources</td>\n",
       "      <td>No Contributors found!</td>\n",
       "      <td>TypeScript 93.2% HTML 4.5% JavaScript 1.3% Oth...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>oven-sh / bun</td>\n",
       "      <td>Incredibly fast JavaScript runtime, bundler, t...</td>\n",
       "      <td>586</td>\n",
       "      <td>Zig 60.5% C++ 23.7% JavaScript 5.7% TypeScript...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>OpenZeppelin / openzeppelin-contracts</td>\n",
       "      <td>OpenZeppelin Contracts is a library for secure...</td>\n",
       "      <td>435</td>\n",
       "      <td>JavaScript 46.7% Solidity 41.4% Ruby 11.1% Oth...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>mlabonne / llm-course</td>\n",
       "      <td>Course to get into Large Language Models (LLMs...</td>\n",
       "      <td>2</td>\n",
       "      <td>Jupyter Notebook 100.0%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Repository Title  \\\n",
       "0                          HardhatChad / ore-cli   \n",
       "1                           plandex-ai / plandex   \n",
       "2                anthropics / anthropic-cookbook   \n",
       "3                              HardhatChad / ore   \n",
       "4                      ixartz / SaaS-Boilerplate   \n",
       "5                          AstroNvim / AstroNvim   \n",
       "6                         availproject / availup   \n",
       "7                      nilsherzig / LLocalSearch   \n",
       "8                         FoundationVision / VAR   \n",
       "9                    firebase / firebase-ios-sdk   \n",
       "10               bradtraversy / 50projects50days   \n",
       "11                     princeton-nlp / SWE-agent   \n",
       "12               PKUFlyingPig / cs-self-learning   \n",
       "13                             searxng / searxng   \n",
       "14                       ossu / computer-science   \n",
       "15         ryanmcdermott / clean-code-javascript   \n",
       "16  avito-tech / backend-trainee-assignment-2024   \n",
       "17                              dockur / windows   \n",
       "18       awesome-selfhosted / awesome-selfhosted   \n",
       "19                                wandb / openui   \n",
       "20         mahmoud / awesome-python-applications   \n",
       "21                      HerbertHe / iptv-sources   \n",
       "22                                 oven-sh / bun   \n",
       "23         OpenZeppelin / openzeppelin-contracts   \n",
       "24                         mlabonne / llm-course   \n",
       "\n",
       "                               Repository Description      Contributors Count  \\\n",
       "0        No description, website, or topics provided.                       4   \n",
       "1               An AI coding engine for complex tasks                       7   \n",
       "2   A collection of notebooks/recipes showcasing s...                      12   \n",
       "3        No description, website, or topics provided.  No Contributors found!   \n",
       "4   🚀🎉📚 SaaS Boilerplate built with Next.js + Tail...                       4   \n",
       "5   AstroNvim is an aesthetic and feature-rich neo...                      79   \n",
       "6        No description, website, or topics provided.                       3   \n",
       "7   LLocalSearch is a completely locally running s...                       6   \n",
       "8   [GPT beats diffusion🔥] [scaling laws in visual...                       2   \n",
       "9              Firebase SDK for Apple App Development                     221   \n",
       "10         50+ mini web projects using HTML, CSS & JS                      38   \n",
       "11  SWE-agent takes a GitHub issue and tries to au...                      14   \n",
       "12                                            计算机自学指南                     120   \n",
       "13  SearXNG is a free internet metasearch engine w...                     220   \n",
       "14  🎓 Path to a free self-taught education in Comp...                     140   \n",
       "15       🛁 Clean Code concepts adapted for JavaScript                     112   \n",
       "16       No description, website, or topics provided.  No Contributors found!   \n",
       "17                     Windows in a Docker container.                       4   \n",
       "18  A list of Free Software network services and w...                   1,260   \n",
       "19  OpenUI let's you describe UI using your imagin...                       7   \n",
       "20  💿 Free software that works great, and also hap...                      33   \n",
       "21                            Autoupdate iptv sources  No Contributors found!   \n",
       "22  Incredibly fast JavaScript runtime, bundler, t...                     586   \n",
       "23  OpenZeppelin Contracts is a library for secure...                     435   \n",
       "24  Course to get into Large Language Models (LLMs...                       2   \n",
       "\n",
       "                                        Language Used  \n",
       "0                                         Rust 100.0%  \n",
       "1                      Go 97.4% Shell 1.3% Other 1.3%  \n",
       "2                             Jupyter Notebook 100.0%  \n",
       "3                                         Rust 100.0%  \n",
       "4   TypeScript 93.3% JavaScript 4.8% CSS 1.7% Shel...  \n",
       "5                                          Lua 100.0%  \n",
       "6                                        Shell 100.0%  \n",
       "7   Go 49.7% Svelte 40.4% TypeScript 2.8% Makefile...  \n",
       "8                  Python 93.7% Jupyter Notebook 6.3%  \n",
       "9   Objective-C 44.3% C++ 37.3% Swift 10.2% Object...  \n",
       "10              CSS 38.5% HTML 31.6% JavaScript 29.9%  \n",
       "11  Python 77.9% Shell 16.1% CSS 2.8% JavaScript 2...  \n",
       "12                                        HTML 100.0%  \n",
       "13  Python 74.0% Shell 10.2% HTML 6.3% Less 5.0% J...  \n",
       "14                           No language usage found!  \n",
       "15                                  JavaScript 100.0%  \n",
       "16                           No language usage found!  \n",
       "17                        Shell 98.3% Dockerfile 1.7%  \n",
       "18                           No language usage found!  \n",
       "19  TypeScript 59.2% Python 33.3% HTML 5.2% CSS 0....  \n",
       "20                            Jupyter Notebook 100.0%  \n",
       "21  TypeScript 93.2% HTML 4.5% JavaScript 1.3% Oth...  \n",
       "22  Zig 60.5% C++ 23.7% JavaScript 5.7% TypeScript...  \n",
       "23  JavaScript 46.7% Solidity 41.4% Ruby 11.1% Oth...  \n",
       "24                            Jupyter Notebook 100.0%  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating dataframe\n",
    "import pandas as pd\n",
    "github_df = pd.DataFrame({'Repository Title':repository_title, 'Repository Description':repository_description, 'Contributors Count':contributors_count, 'Language Used':language_used})\n",
    "github_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b2f03fcc-6fcb-46e8-b15f-99d479e8d265",
   "metadata": {},
   "outputs": [],
   "source": [
    "github_driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "751a99a6-8c87-45ca-8d5e-fa6ce3c97827",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6fb556ac-f0f3-42a0-8d6b-150dd04ab2d5",
   "metadata": {},
   "source": [
    "Q5. Scrape the details of top 100 songs on billiboard.com.\n",
    "\n",
    "Url = https:/www.billboard.com/\n",
    "\n",
    "You have to find the following details:\n",
    "\n",
    "A) Song name\n",
    "B) Artist name\n",
    "C) Last week rank\n",
    "D) Peak rank\n",
    "E) Weeks on board\n",
    "\n",
    "Note: - From the home page you have to click on the charts option then hot 100-page link through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bb4d03ec-4b4d-40d6-bf4f-b3b7fced246e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing Selenium, pandas, selenium webdriver, warnings, and time\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import requests\n",
    "import re\n",
    "\n",
    "#importing selenium webdriver\n",
    "from selenium import webdriver\n",
    "\n",
    "#importing warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from time import sleep\n",
    "from selenium.webdriver import ActionChains\n",
    "from selenium.webdriver.common.actions.action_builder import ActionBuilder\n",
    "from selenium.webdriver.common.actions.mouse_button import MouseButton\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "#Importing Exceptions\n",
    "from selenium.common.exceptions import NoSuchElementException as NSEE\n",
    "from selenium.common.exceptions import StaleElementReferenceException as SERE\n",
    "from selenium.common.exceptions import ElementNotInteractableException as ENIE\n",
    "from selenium.common.exceptions import TimeoutException as TE\n",
    "from selenium.common.exceptions import InvalidSelectorException as ISE\n",
    "from selenium.common.exceptions import ElementClickInterceptedException as ECIE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "da975053-5c28-47c4-9db2-7ee65f9bebf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "billiboard_driver = webdriver.Chrome() #opening automated chrome browser using selenium driver\n",
    "billiboard_driver.maximize_window() #maximize window\n",
    "billiboard_url =  'https:/www.billboard.com/' #url\n",
    "billiboard_driver.get(billiboard_url) #opening the webpage on automated chrome browser\n",
    "time.sleep(7) #asking driver to wait for 7 seconds\n",
    "\n",
    "#navigating to the required page\n",
    "try:\n",
    "    charts_menu = billiboard_driver.find_element(By.XPATH,'//div[@class=\"main-menu-container js-hide-when-sticky\"]/div/div/div[2]/div[2]/div/div/nav/ul/li[1]/a')\n",
    "    charts_menu.click()\n",
    "except NSEE:\n",
    "    print(\"Exception Raised: \\n\", NSEE)\n",
    "except SERE:\n",
    "    print(\"Exception Raised: \\n\", SERE)\n",
    "except ENIE:\n",
    "    print(\"Exception Raised: \\n\", ENIE)\n",
    "except TE:\n",
    "    print(\"Exception Raised: \\n\", TE)\n",
    "except ISE:\n",
    "    print(\"Exception Raised: \\n\", ISE)\n",
    "except ECIE:\n",
    "    print(\"Exception Raised: \\n\", ECIE)\n",
    "\n",
    "time.sleep(2)\n",
    "#scrolling down webpage \n",
    "for _ in range(10):\n",
    "    billiboard_driver.execute_script(\"window.scrollBy(0,400)\")\n",
    "\n",
    "time.sleep(2)\n",
    "\n",
    "try:\n",
    "    hot_100 = billiboard_driver.find_element(By.XPATH, '//div[@class=\"chart-landing-background-mobile\"]/div/div/div[3]/a')\n",
    "    hot_100.click()\n",
    "except NSEE:\n",
    "    print(\"Exception Raised: \\n\", NSEE)\n",
    "except SERE:\n",
    "    print(\"Exception Raised: \\n\", SERE)\n",
    "except ENIE:\n",
    "    print(\"Exception Raised: \\n\", ENIE)\n",
    "except TE:\n",
    "    print(\"Exception Raised: \\n\", TE)\n",
    "except ISE:\n",
    "    print(\"Exception Raised: \\n\", ISE)\n",
    "except ECIE:\n",
    "    print(\"Exception Raised: \\n\", ECIE)\n",
    "\n",
    "\n",
    "time.sleep(2)\n",
    "\n",
    "#scraping for song name\n",
    "song_name = []\n",
    "song = billiboard_driver.find_elements(By.XPATH, '//li[@class=\"lrv-u-width-100p\"]/ul/li[1]/h3')\n",
    "for i in song:\n",
    "    try:\n",
    "        song_name.append(i.text)\n",
    "    except NSEE:\n",
    "        song_name.append('--')\n",
    "    except SERE:\n",
    "        song_name.append('--')\n",
    "    except ENIE:\n",
    "        song_name.append('--')\n",
    "    except TE:\n",
    "        song_name.append('--')\n",
    "    except ISE:\n",
    "        song_name.append('--')\n",
    "    except ECIE:\n",
    "        song_name.append('--')\n",
    "\n",
    "#scraping for artist name\n",
    "artist_name = []\n",
    "artist = billiboard_driver.find_elements(By.XPATH, '//li[@class=\"lrv-u-width-100p\"]/ul/li[1]/span')\n",
    "for i in artist:\n",
    "    try:\n",
    "        artist_name.append(i.text)\n",
    "    except NSEE:\n",
    "        artist_name.append('--')\n",
    "    except SERE:\n",
    "        artist_name.append('--')\n",
    "    except ENIE:\n",
    "        artist_name.append('--')\n",
    "    except TE:\n",
    "        artist_name.append('--')\n",
    "    except ISE:\n",
    "        artist_name.append('--')\n",
    "    except ECIE:\n",
    "        artist_name.append('--')\n",
    "\n",
    "#scraping for last week rank\n",
    "last_week_rank = []\n",
    "last_rank = billiboard_driver.find_elements(By.XPATH, '//li[@class=\"lrv-u-width-100p\"]/ul/li[4]/span')\n",
    "for i in last_rank:\n",
    "    try:\n",
    "        last_week_rank.append(i.text)\n",
    "    except NSEE:\n",
    "        last_week_rank.append('--')\n",
    "    except SERE:\n",
    "        last_week_rank.append('--')\n",
    "    except ENIE:\n",
    "        last_week_rank.append('--')\n",
    "    except TE:\n",
    "        last_week_rank.append('--')\n",
    "    except ISE:\n",
    "        last_week_rank.append('--')\n",
    "    except ECIE:\n",
    "        last_week_rank.append('--')\n",
    "\n",
    "#scraping for peak rank\n",
    "peak_rank = []\n",
    "rank = billiboard_driver.find_elements(By.XPATH, '//li[@class=\"lrv-u-width-100p\"]/ul/li[5]/span')\n",
    "for i in rank:\n",
    "    try:\n",
    "        peak_rank.append(i.text)\n",
    "    except NSEE:\n",
    "        peak_rank.append('--')\n",
    "    except SERE:\n",
    "        peak_rank.append('--')\n",
    "    except ENIE:\n",
    "        peak_rank.append('--')\n",
    "    except TE:\n",
    "        peak_rank.append('--')\n",
    "    except ISE:\n",
    "        peak_rank.append('--')\n",
    "    except ECIE:\n",
    "        peak_rank.append('--')\n",
    "\n",
    "#scraping for weeks on board\n",
    "weeks_on_board = []\n",
    "on_board = billiboard_driver.find_elements(By.XPATH, '//li[@class=\"lrv-u-width-100p\"]/ul/li[6]/span')\n",
    "for i in on_board:\n",
    "    try:\n",
    "        weeks_on_board.append(i.text)\n",
    "    except NSEE:\n",
    "        weeks_on_board.append('--')\n",
    "    except SERE:\n",
    "        weeks_on_board.append('--')\n",
    "    except ENIE:\n",
    "        weeks_on_board.append('--')\n",
    "    except TE:\n",
    "        weeks_on_board.append('--')\n",
    "    except ISE:\n",
    "        weeks_on_board.append('--')\n",
    "    except ECIE:\n",
    "        weeks_on_board.append('--')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "90ca3aa7-ed9f-4ce1-b07b-7e8caec05eb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 100 100 100 100\n"
     ]
    }
   ],
   "source": [
    "print(len(song_name), len(artist_name), len(last_week_rank), len(peak_rank), len(weeks_on_board))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4fb4e8ff-d529-4ac5-8660-c337b97ec662",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Song Name</th>\n",
       "      <th>Artist Name</th>\n",
       "      <th>Last Week Rank</th>\n",
       "      <th>Peak Rank</th>\n",
       "      <th>Weeks on Board</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Like That</td>\n",
       "      <td>Future, Metro Boomin &amp; Kendrick Lamar</td>\n",
       "      <td>-</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Type Shit</td>\n",
       "      <td>Future, Metro Boomin, Travis Scott &amp; Playboi C...</td>\n",
       "      <td>-</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Beautiful Things</td>\n",
       "      <td>Benson Boone</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lose Control</td>\n",
       "      <td>Teddy Swims</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Too Sweet</td>\n",
       "      <td>Hozier</td>\n",
       "      <td>-</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>La Victima</td>\n",
       "      <td>Xavi</td>\n",
       "      <td>77</td>\n",
       "      <td>46</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Tucson Too Late</td>\n",
       "      <td>Jordan Davis</td>\n",
       "      <td>81</td>\n",
       "      <td>81</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Empire Now</td>\n",
       "      <td>Hozier</td>\n",
       "      <td>-</td>\n",
       "      <td>98</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Girl I've Always Been</td>\n",
       "      <td>Olivia Rodrigo</td>\n",
       "      <td>-</td>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Outskirts</td>\n",
       "      <td>Sam Hunt</td>\n",
       "      <td>92</td>\n",
       "      <td>92</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Song Name                                        Artist Name  \\\n",
       "0               Like That              Future, Metro Boomin & Kendrick Lamar   \n",
       "1               Type Shit  Future, Metro Boomin, Travis Scott & Playboi C...   \n",
       "2        Beautiful Things                                       Benson Boone   \n",
       "3            Lose Control                                        Teddy Swims   \n",
       "4               Too Sweet                                             Hozier   \n",
       "..                    ...                                                ...   \n",
       "95             La Victima                                               Xavi   \n",
       "96        Tucson Too Late                                       Jordan Davis   \n",
       "97             Empire Now                                             Hozier   \n",
       "98  Girl I've Always Been                                     Olivia Rodrigo   \n",
       "99              Outskirts                                           Sam Hunt   \n",
       "\n",
       "   Last Week Rank Peak Rank Weeks on Board  \n",
       "0               -         1              1  \n",
       "1               -         2              1  \n",
       "2               2         2             10  \n",
       "3               1         1             33  \n",
       "4               -         5              1  \n",
       "..            ...       ...            ...  \n",
       "95             77        46             15  \n",
       "96             81        81              4  \n",
       "97              -        98              1  \n",
       "98              -        99              1  \n",
       "99             92        92              3  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating dataframe\n",
    "import pandas as pd\n",
    "billboard_df = pd.DataFrame({'Song Name':song_name, 'Artist Name':artist_name, 'Last Week Rank':last_week_rank, 'Peak Rank':peak_rank, 'Weeks on Board':weeks_on_board})\n",
    "billboard_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f49e0245-6d64-45c3-ba2a-6544451bee00",
   "metadata": {},
   "outputs": [],
   "source": [
    "billiboard_driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11de9314-452e-4ece-9cf6-aa1115c8689e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f25d9242-9f8c-4542-86c5-1fb17a993601",
   "metadata": {},
   "source": [
    "Q6. Scrape the details of Highest selling novels.\n",
    "    \n",
    "A) Book name\n",
    "B) Author name\n",
    "C) Volumes sold\n",
    "D) Publisher\n",
    "E) Genre\n",
    "\n",
    "Url - https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "86521a4b-451f-455f-b512-27405548037b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing Selenium, pandas, selenium webdriver, warnings, and time\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import requests\n",
    "import re\n",
    "\n",
    "#importing selenium webdriver\n",
    "from selenium import webdriver\n",
    "\n",
    "#importing warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from time import sleep\n",
    "from selenium.webdriver import ActionChains\n",
    "from selenium.webdriver.common.actions.action_builder import ActionBuilder\n",
    "from selenium.webdriver.common.actions.mouse_button import MouseButton\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "#Importing Exceptions\n",
    "from selenium.common.exceptions import NoSuchElementException as NSEE\n",
    "from selenium.common.exceptions import StaleElementReferenceException as SERE\n",
    "from selenium.common.exceptions import ElementNotInteractableException as ENIE\n",
    "from selenium.common.exceptions import TimeoutException as TE\n",
    "from selenium.common.exceptions import InvalidSelectorException as ISE\n",
    "from selenium.common.exceptions import ElementClickInterceptedException as ECIE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "baf4e906-7bd0-4bda-a4aa-09f1a318c6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "novels_driver = webdriver.Chrome() #opening automated chrome browser using selenium driver\n",
    "novels_driver.maximize_window() #maximize window\n",
    "novels_url =  'https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare' #url\n",
    "novels_driver.get(novels_url) #opening the webpage on automated chrome browser\n",
    "time.sleep(2) #asking driver to wait for 2 seconds\n",
    "\n",
    "#scraping for book name\n",
    "book_name = []\n",
    "book = novels_driver.find_elements(By.XPATH, '//table[@class=\"in-article sortable\"]/tbody/tr/td[2]')\n",
    "for i in book:\n",
    "    try:\n",
    "        book_name.append(i.text)\n",
    "    except NSEE:\n",
    "        book_name.append('--')\n",
    "    except SERE:\n",
    "        book_name.append('--')\n",
    "    except ENIE:\n",
    "        book_name.append('--')\n",
    "    except TE:\n",
    "        book_name.append('--')\n",
    "    except ISE:\n",
    "        book_name.append('--')\n",
    "    except ECIE:\n",
    "        book_name.append('--')\n",
    "\n",
    "#scraping for author name\n",
    "author_name = []\n",
    "author = novels_driver.find_elements(By.XPATH, '//table[@class=\"in-article sortable\"]/tbody/tr/td[3]')\n",
    "for i in author:\n",
    "    try:\n",
    "        author_name.append(i.text)\n",
    "    except NSEE:\n",
    "        author_name.append('--')\n",
    "    except SERE:\n",
    "        author_name.append('--')\n",
    "    except ENIE:\n",
    "        author_name.append('--')\n",
    "    except TE:\n",
    "        author_name.append('--')\n",
    "    except ISE:\n",
    "        author_name.append('--')\n",
    "    except ECIE:\n",
    "        author_name.append('--')\n",
    "\n",
    "#scraping for Volumes sold\n",
    "volumes_sold = []\n",
    "sold = novels_driver.find_elements(By.XPATH, '//table[@class=\"in-article sortable\"]/tbody/tr/td[4]')\n",
    "for i in sold:\n",
    "    try:\n",
    "        volumes_sold.append(i.text)\n",
    "    except NSEE:\n",
    "        volumes_sold.append('--')\n",
    "    except SERE:\n",
    "        volumes_sold.append('--')\n",
    "    except ENIE:\n",
    "        volumes_sold.append('--')\n",
    "    except TE:\n",
    "        volumes_sold.append('--')\n",
    "    except ISE:\n",
    "        volumes_sold.append('--')\n",
    "    except ECIE:\n",
    "        volumes_sold.append('--')\n",
    "\n",
    "#scraping for Publisher\n",
    "book_publisher = []\n",
    "publisher = novels_driver.find_elements(By.XPATH, '//table[@class=\"in-article sortable\"]/tbody/tr/td[5]')\n",
    "for i in publisher:\n",
    "    try:\n",
    "        book_publisher.append(i.text)\n",
    "    except NSEE:\n",
    "        book_publisher.append('--')\n",
    "    except SERE:\n",
    "        book_publisher.append('--')\n",
    "    except ENIE:\n",
    "        book_publisher.append('--')\n",
    "    except TE:\n",
    "        book_publisher.append('--')\n",
    "    except ISE:\n",
    "        book_publisher.append('--')\n",
    "    except ECIE:\n",
    "        book_publisher.append('--')\n",
    "\n",
    "#scraping for Genre\n",
    "book_genre = []\n",
    "genre = novels_driver.find_elements(By.XPATH, '//table[@class=\"in-article sortable\"]/tbody/tr/td[6]')\n",
    "for i in genre:\n",
    "    try:\n",
    "        book_genre.append(i.text)\n",
    "    except NSEE:\n",
    "        book_genre.append('--')\n",
    "    except SERE:\n",
    "        book_genre.append('--')\n",
    "    except ENIE:\n",
    "        book_genre.append('--')\n",
    "    except TE:\n",
    "        book_genre.append('--')\n",
    "    except ISE:\n",
    "        book_genre.append('--')\n",
    "    except ECIE:\n",
    "        book_genre.append('--')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3dd36933-432e-4c8f-be2f-ff8f2cb14cdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 100 100 100 100\n"
     ]
    }
   ],
   "source": [
    "print(len(book_name), len(author_name), len(volumes_sold), len(book_publisher), len(book_genre))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b7d66f6c-5432-4ed4-880b-833e0985f279",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Book Name</th>\n",
       "      <th>Author Name</th>\n",
       "      <th>Volumes Sold</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Da Vinci Code,The</td>\n",
       "      <td>Brown, Dan</td>\n",
       "      <td>5,094,805</td>\n",
       "      <td>Transworld</td>\n",
       "      <td>Crime, Thriller &amp; Adventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Harry Potter and the Deathly Hallows</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,475,152</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Harry Potter and the Philosopher's Stone</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,200,654</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Harry Potter and the Order of the Phoenix</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,179,479</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fifty Shades of Grey</td>\n",
       "      <td>James, E. L.</td>\n",
       "      <td>3,758,936</td>\n",
       "      <td>Random House</td>\n",
       "      <td>Romance &amp; Sagas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Ghost,The</td>\n",
       "      <td>Harris, Robert</td>\n",
       "      <td>807,311</td>\n",
       "      <td>Random House</td>\n",
       "      <td>General &amp; Literary Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Happy Days with the Naked Chef</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>794,201</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Hunger Games,The:Hunger Games Trilogy</td>\n",
       "      <td>Collins, Suzanne</td>\n",
       "      <td>792,187</td>\n",
       "      <td>Scholastic Ltd.</td>\n",
       "      <td>Young Adult Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Lost Boy,The:A Foster Child's Search for the L...</td>\n",
       "      <td>Pelzer, Dave</td>\n",
       "      <td>791,507</td>\n",
       "      <td>Orion</td>\n",
       "      <td>Biography: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Jamie's Ministry of Food:Anyone Can Learn to C...</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>791,095</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Book Name       Author Name  \\\n",
       "0                                   Da Vinci Code,The        Brown, Dan   \n",
       "1                Harry Potter and the Deathly Hallows     Rowling, J.K.   \n",
       "2            Harry Potter and the Philosopher's Stone     Rowling, J.K.   \n",
       "3           Harry Potter and the Order of the Phoenix     Rowling, J.K.   \n",
       "4                                Fifty Shades of Grey      James, E. L.   \n",
       "..                                                ...               ...   \n",
       "95                                          Ghost,The    Harris, Robert   \n",
       "96                     Happy Days with the Naked Chef     Oliver, Jamie   \n",
       "97              Hunger Games,The:Hunger Games Trilogy  Collins, Suzanne   \n",
       "98  Lost Boy,The:A Foster Child's Search for the L...      Pelzer, Dave   \n",
       "99  Jamie's Ministry of Food:Anyone Can Learn to C...     Oliver, Jamie   \n",
       "\n",
       "   Volumes Sold        Publisher                        Genre  \n",
       "0     5,094,805       Transworld  Crime, Thriller & Adventure  \n",
       "1     4,475,152       Bloomsbury           Children's Fiction  \n",
       "2     4,200,654       Bloomsbury           Children's Fiction  \n",
       "3     4,179,479       Bloomsbury           Children's Fiction  \n",
       "4     3,758,936     Random House              Romance & Sagas  \n",
       "..          ...              ...                          ...  \n",
       "95      807,311     Random House   General & Literary Fiction  \n",
       "96      794,201          Penguin        Food & Drink: General  \n",
       "97      792,187  Scholastic Ltd.          Young Adult Fiction  \n",
       "98      791,507            Orion           Biography: General  \n",
       "99      791,095          Penguin        Food & Drink: General  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating dataframe\n",
    "import pandas as pd\n",
    "novels_df = pd.DataFrame({'Book Name':book_name, 'Author Name':author_name, 'Volumes Sold':volumes_sold, 'Publisher':book_publisher, 'Genre':book_genre})\n",
    "novels_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4be3b4a8-a373-4a52-9378-435d644fea3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "novels_driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c3f0532-595f-477b-95c3-be4aa0c81fa5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6f14d452-922a-434b-9a33-56cb69742fae",
   "metadata": {},
   "source": [
    "Q8. Details of Datasets from UCI machine learning repositories.\n",
    "    \n",
    "Url = https://archive.ics.uci.edu/\n",
    "    \n",
    "You have to find the following details:\n",
    "\n",
    "A) Dataset name\n",
    "B) Data type\n",
    "C) Task\n",
    "D) Attribute type\n",
    "E) No of instances\n",
    "F) No of attribute G) Year\n",
    "\n",
    "Note: - from the home page you have to go to the Show All Dataset page through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7b57cc52-2a4e-4b9b-bd81-ac80f8d27172",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing Selenium, pandas, selenium webdriver, warnings, and time\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import requests\n",
    "import re\n",
    "\n",
    "#importing selenium webdriver\n",
    "from selenium import webdriver\n",
    "\n",
    "#importing warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from time import sleep\n",
    "from selenium.webdriver import ActionChains\n",
    "from selenium.webdriver.common.actions.action_builder import ActionBuilder\n",
    "from selenium.webdriver.common.actions.mouse_button import MouseButton\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "#Importing Exceptions\n",
    "from selenium.common.exceptions import NoSuchElementException as NSEE\n",
    "from selenium.common.exceptions import StaleElementReferenceException as SERE\n",
    "from selenium.common.exceptions import ElementNotInteractableException as ENIE\n",
    "from selenium.common.exceptions import TimeoutException as TE\n",
    "from selenium.common.exceptions import InvalidSelectorException as ISE\n",
    "from selenium.common.exceptions import ElementClickInterceptedException as ECIE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9d0c65e7-2dce-4553-8c42-1bc74635152c",
   "metadata": {},
   "outputs": [],
   "source": [
    "archive_driver = webdriver.Chrome() #opening automated chrome browser using selenium driver\n",
    "archive_driver.maximize_window() #maximize window\n",
    "archive_url =  'https://archive.ics.uci.edu/' #url\n",
    "archive_driver.get(archive_url) #opening the webpage on automated chrome browser\n",
    "time.sleep(2) #asking driver to wait for 2 seconds\n",
    "\n",
    "#navigating to the required page\n",
    "try:\n",
    "    dataset_menu = archive_driver.find_element(By.XPATH,'//a[@class=\"btn-primary btn\"]')\n",
    "    dataset_menu.click()\n",
    "except NSEE:\n",
    "    print(\"Exception Raised: \\n\", NSEE)\n",
    "except SERE:\n",
    "    print(\"Exception Raised: \\n\", SERE)\n",
    "except ENIE:\n",
    "    print(\"Exception Raised: \\n\", ENIE)\n",
    "except TE:\n",
    "    print(\"Exception Raised: \\n\", TE)\n",
    "except ISE:\n",
    "    print(\"Exception Raised: \\n\", ISE)\n",
    "except ECIE:\n",
    "    print(\"Exception Raised: \\n\", ECIE)\n",
    "\n",
    "time.sleep(2)\n",
    "\n",
    "#Declaring lists\n",
    "dataset_name = []\n",
    "data_type = []\n",
    "dataset_task = []\n",
    "attribute_type = []\n",
    "no_of_instances = []\n",
    "no_of_attributes = []\n",
    "donated_year = []\n",
    "\n",
    "#getting page url & iterating to next pages\n",
    "url_1 = 'https://archive.ics.uci.edu/datasets?skip=0'\n",
    "url_2 = '&take=10&sort=desc&orderBy=NumHits&search='\n",
    "dataset_url = url_1.replace(\"skip=0\",\"skip=\")\n",
    "for page in range(0, 670, 10):\n",
    "    try:\n",
    "        dataset_page = dataset_url + str(page) + url_2\n",
    "        archive_driver.get(dataset_page)\n",
    "        time.sleep(2)\n",
    "        #Expanding all datasets\n",
    "        try:\n",
    "            expand_all = archive_driver.find_element(By.XPATH,'//div[@class=\"flex flex-wrap items-center gap-4\"]/label[2]')\n",
    "            expand_all.click()\n",
    "        except NSEE:\n",
    "            print(\"Exception Raised: \\n\", NSEE)\n",
    "        except SERE:\n",
    "            print(\"Exception Raised: \\n\", SERE)\n",
    "        except ENIE:\n",
    "            print(\"Exception Raised: \\n\", ENIE)\n",
    "        except TE:\n",
    "            print(\"Exception Raised: \\n\", TE)\n",
    "        except ISE:\n",
    "            print(\"Exception Raised: \\n\", ISE)\n",
    "        except ECIE:\n",
    "            print(\"Exception Raised: \\n\", ECIE)\n",
    "    \n",
    "        time.sleep(2)\n",
    "        #scraping for Dataset Name\n",
    "        d_name = archive_driver.find_elements(By.XPATH, '//h2[@class=\"truncate text-primary\"]')\n",
    "        for i in d_name:\n",
    "            try:\n",
    "                dataset_name.append(i.text)\n",
    "            except NSEE:\n",
    "                dataset_name.append('--')\n",
    "            except SERE:\n",
    "                dataset_name.append('--')\n",
    "            except ENIE:\n",
    "                dataset_name.append('--')\n",
    "            except TE:\n",
    "                dataset_name.append('--')\n",
    "            except ISE:\n",
    "                dataset_name.append('--')\n",
    "            except ECIE:\n",
    "                dataset_name.append('--')\n",
    "    \n",
    "        #scraping for Data type\n",
    "        d_type = archive_driver.find_elements(By.XPATH, '//div[@class=\"my-2 hidden gap-4 md:grid grid-cols-12\"]/div[2]/span')\n",
    "        for i in d_type:\n",
    "            try:\n",
    "                data_type.append(i.text)\n",
    "            except NSEE:\n",
    "                data_type.append('--')\n",
    "            except SERE:\n",
    "                data_type.append('--')\n",
    "            except ENIE:\n",
    "                data_type.append('--')\n",
    "            except TE:\n",
    "                data_type.append('--')\n",
    "            except ISE:\n",
    "                data_type.append('--')\n",
    "            except ECIE:\n",
    "                data_type.append('--')\n",
    "    \n",
    "        #scraping for Dataset task\n",
    "        d_task = archive_driver.find_elements(By.XPATH, '//div[@class=\"my-2 hidden gap-4 md:grid grid-cols-12\"]/div[1]/span')\n",
    "        for i in d_task:\n",
    "            try:\n",
    "                dataset_task.append(i.text)\n",
    "            except NSEE:\n",
    "                dataset_task.append('--')\n",
    "            except SERE:\n",
    "                dataset_task.append('--')\n",
    "            except ENIE:\n",
    "                dataset_task.append('--')\n",
    "            except TE:\n",
    "                dataset_task.append('--')\n",
    "            except ISE:\n",
    "                dataset_task.append('--')\n",
    "            except ECIE:\n",
    "                dataset_task.append('--')\n",
    "    \n",
    "        #scraping for Dataset attribute type\n",
    "        a_type = archive_driver.find_elements(By.XPATH, '//table[@class=\"col-span-full my-2 table sm:col-start-2\"]/tbody/tr/td[2]')\n",
    "        for i in a_type:\n",
    "            try:\n",
    "                attribute_type.append(i.text)\n",
    "            except NSEE:\n",
    "                attribute_type.append('--')\n",
    "            except SERE:\n",
    "                attribute_type.append('--')\n",
    "            except ENIE:\n",
    "                attribute_type.append('--')\n",
    "            except TE:\n",
    "                attribute_type.append('--')\n",
    "            except ISE:\n",
    "                attribute_type.append('--')\n",
    "            except ECIE:\n",
    "                attribute_type.append('--')\n",
    "    \n",
    "        #scraping for Number of instances\n",
    "        instances = archive_driver.find_elements(By.XPATH, '//div[@class=\"my-2 hidden gap-4 md:grid grid-cols-12\"]/div[3]/span')\n",
    "        for i in instances:\n",
    "            try:\n",
    "                if i.text == '':\n",
    "                    no_of_instances.append('--')\n",
    "                else:\n",
    "                    no_of_instances.append(i.text.split()[0])\n",
    "            except NSEE:\n",
    "                no_of_instances.append('--')\n",
    "            except SERE:\n",
    "                no_of_instances.append('--')\n",
    "            except ENIE:\n",
    "                no_of_instances.append('--')\n",
    "            except TE:\n",
    "                no_of_instances.append('--')\n",
    "            except ISE:\n",
    "                no_of_instances.append('--')\n",
    "            except ECIE:\n",
    "                no_of_instances.append('--')\n",
    "    \n",
    "        #scraping for Number of attributes\n",
    "        attributes = archive_driver.find_elements(By.XPATH, '//div[@class=\"my-2 hidden gap-4 md:grid grid-cols-12\"]/div[4]/span')\n",
    "        for i in attributes:\n",
    "            try:\n",
    "                if i.text == '':\n",
    "                    no_of_attributes.append('--')\n",
    "                else:\n",
    "                    no_of_attributes.append(i.text.split()[0])\n",
    "            except NSEE:\n",
    "                no_of_attributes.append('--')\n",
    "            except SERE:\n",
    "                no_of_attributes.append('--')\n",
    "            except ENIE:\n",
    "                no_of_attributes.append('--')\n",
    "            except TE:\n",
    "                no_of_attributes.append('--')\n",
    "            except ISE:\n",
    "                no_of_attributes.append('--')\n",
    "            except ECIE:\n",
    "                no_of_attributes.append('--')\n",
    "    \n",
    "        #scraping for dataset donated year\n",
    "        year = archive_driver.find_elements(By.XPATH, '//table[@class=\"col-span-full my-2 table sm:col-start-2\"]/tbody/tr/td[3]')\n",
    "        for i in year:\n",
    "            try:\n",
    "                if i.text == 'N/A':\n",
    "                    donated_year.append('N/A')\n",
    "                else:\n",
    "                    donated_year.append(i.text.split('/')[2])\n",
    "            except NSEE:\n",
    "                donated_year.append('--')\n",
    "            except SERE:\n",
    "                donated_year.append('--')\n",
    "            except ENIE:\n",
    "                donated_year.append('--')\n",
    "            except TE:\n",
    "                donated_year.append('--')\n",
    "            except ISE:\n",
    "                donated_year.append('--')\n",
    "            except ECIE:\n",
    "                donated_year.append('--')\n",
    "    except:\n",
    "        print('URL not found!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c3807862-b24b-4eb0-90c1-57e4ca43f8bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "664 664 664 664 664 664 664\n"
     ]
    }
   ],
   "source": [
    "print(len(dataset_name), len(data_type), len(dataset_task), len(attribute_type), len(no_of_instances), len(no_of_attributes), len(donated_year))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "abd63b8d-835d-416b-8753-dac7560914e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset Name</th>\n",
       "      <th>Data Type</th>\n",
       "      <th>Task</th>\n",
       "      <th>Attribute Type</th>\n",
       "      <th>Number of Instances</th>\n",
       "      <th>Number of Attributes</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Iris</td>\n",
       "      <td>Tabular</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Real</td>\n",
       "      <td>150</td>\n",
       "      <td>4</td>\n",
       "      <td>1988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dry Bean</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Integer, Real</td>\n",
       "      <td>13.61K</td>\n",
       "      <td>16</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Heart Disease</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>303</td>\n",
       "      <td>13</td>\n",
       "      <td>1988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rice (Cammeo and Osmancik)</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Real</td>\n",
       "      <td>3.81K</td>\n",
       "      <td>7</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adult</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer</td>\n",
       "      <td>48.84K</td>\n",
       "      <td>14</td>\n",
       "      <td>1996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>659</th>\n",
       "      <td>Undocumented</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>N/A</td>\n",
       "      <td>--</td>\n",
       "      <td>--</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>660</th>\n",
       "      <td>PMU-UD</td>\n",
       "      <td>Univariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td></td>\n",
       "      <td>5.18K</td>\n",
       "      <td>9</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>661</th>\n",
       "      <td>DGP2 - The Second Data Generation Program</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Real</td>\n",
       "      <td>--</td>\n",
       "      <td>--</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>662</th>\n",
       "      <td>EBL Domain Theories</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>N/A</td>\n",
       "      <td>--</td>\n",
       "      <td>--</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>663</th>\n",
       "      <td>Sattriya_Dance_Single_Hand_Gestures Dataset</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>N/A</td>\n",
       "      <td>1.45K</td>\n",
       "      <td>--</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>664 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Dataset Name     Data Type  \\\n",
       "0                                           Iris       Tabular   \n",
       "1                                       Dry Bean  Multivariate   \n",
       "2                                  Heart Disease  Multivariate   \n",
       "3                     Rice (Cammeo and Osmancik)  Multivariate   \n",
       "4                                          Adult  Multivariate   \n",
       "..                                           ...           ...   \n",
       "659                                 Undocumented                 \n",
       "660                                       PMU-UD    Univariate   \n",
       "661    DGP2 - The Second Data Generation Program                 \n",
       "662                          EBL Domain Theories                 \n",
       "663  Sattriya_Dance_Single_Hand_Gestures Dataset  Multivariate   \n",
       "\n",
       "               Task              Attribute Type Number of Instances  \\\n",
       "0    Classification                        Real                 150   \n",
       "1    Classification               Integer, Real              13.61K   \n",
       "2    Classification  Categorical, Integer, Real                 303   \n",
       "3    Classification                        Real               3.81K   \n",
       "4    Classification        Categorical, Integer              48.84K   \n",
       "..              ...                         ...                 ...   \n",
       "659                                         N/A                  --   \n",
       "660  Classification                                           5.18K   \n",
       "661                                        Real                  --   \n",
       "662                                         N/A                  --   \n",
       "663  Classification                         N/A               1.45K   \n",
       "\n",
       "    Number of Attributes  Year  \n",
       "0                      4  1988  \n",
       "1                     16  2020  \n",
       "2                     13  1988  \n",
       "3                      7  2019  \n",
       "4                     14  1996  \n",
       "..                   ...   ...  \n",
       "659                   --   N/A  \n",
       "660                    9  2018  \n",
       "661                   --   N/A  \n",
       "662                   --   N/A  \n",
       "663                   --  2019  \n",
       "\n",
       "[664 rows x 7 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating dataframe\n",
    "import pandas as pd\n",
    "dataset_df = pd.DataFrame({'Dataset Name':dataset_name, 'Data Type':data_type, 'Task':dataset_task, 'Attribute Type':attribute_type, 'Number of Instances':no_of_instances, 'Number of Attributes':no_of_attributes, 'Year':donated_year})\n",
    "dataset_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5354cf1c-697e-4bfd-82df-9193b0ac78c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "archive_driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77cb300a-0d2f-4233-85b4-c5b0fb570f9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "de326d42-0000-4edf-8a23-7b3446ca9ae0",
   "metadata": {},
   "source": [
    "Q7. Scrape the details most watched tv series of all time from imdb.com.\n",
    "\n",
    "Url = https://www.imdb.com/list/ls095964455/\n",
    "\n",
    "You have to find the following details:\n",
    "\n",
    "A) Name\n",
    "B) Year span\n",
    "C) Genre\n",
    "D) Run time\n",
    "E) Ratings\n",
    "F) Votes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1fb32291-457d-46b2-afde-0137e39c54b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing Selenium, pandas, selenium webdriver, warnings, and time\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import requests\n",
    "import re\n",
    "\n",
    "#importing selenium webdriver\n",
    "from selenium import webdriver\n",
    "\n",
    "#importing warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from time import sleep\n",
    "from selenium.webdriver import ActionChains\n",
    "from selenium.webdriver.common.actions.action_builder import ActionBuilder\n",
    "from selenium.webdriver.common.actions.mouse_button import MouseButton\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "#Importing Exceptions\n",
    "from selenium.common.exceptions import NoSuchElementException as NSEE\n",
    "from selenium.common.exceptions import StaleElementReferenceException as SERE\n",
    "from selenium.common.exceptions import ElementNotInteractableException as ENIE\n",
    "from selenium.common.exceptions import TimeoutException as TE\n",
    "from selenium.common.exceptions import InvalidSelectorException as ISE\n",
    "from selenium.common.exceptions import ElementClickInterceptedException as ECIE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "692572f6-0131-4e3b-be52-652e8120bdfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_driver = webdriver.Chrome() #opening automated chrome browser using selenium driver\n",
    "imdb_driver.maximize_window() #maximize window\n",
    "imdb_url =  'https://www.imdb.com/list/ls095964455/' #url\n",
    "imdb_driver.get(imdb_url) #opening the webpage on automated chrome browser\n",
    "time.sleep(2) #asking driver to wait for 2 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1aba3d29-13e8-4dd0-8505-37e63adcec6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_driver.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
